{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMGIjAHcKEo7",
    "outputId": "72280ca0-2171-4346-cb23-93ab94d52ad2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    repo_name = \"dgcnz/dl2\"\n",
    "    url = f\"https://{userdata.get('gh_pat')}@github.com/{repo_name}.git\"\n",
    "    !git clone {url}\n",
    "    print(\"\\nCurrent Directory:\")\n",
    "    %cd dl2\n",
    "    #!pip install torch torchvision numpy matplotlib git+https://github.com/AMLab-Amsterdam/lie_learn escnn scipy\n",
    "    !pip install torchvision git+https://github.com/AMLab-Amsterdam/lie_learn escnn lightning wandb git+https://github.com/dgcnz/neuralyze\n",
    "    #!pip install -r requirements.txt\n",
    "\n",
    "\n",
    "else:  # automatically checks if the current directory is 'repo name'\n",
    "    curdir = Path.cwd()\n",
    "    print(\"Current Directory\", curdir)\n",
    "    assert (\n",
    "        curdir.name == \"dl2\" or curdir.parent.name == \"dl2\"\n",
    "    ), \"Notebook cwd has to be on the project root\"\n",
    "    if curdir.name == \"notebooks\":\n",
    "        %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDX9lHpDWOWm",
    "outputId": "b48128bb-db7b-4127-f7f2-384822f6269b"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=userdata.get(\"wandb_key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AkBacsIOrYJ",
    "outputId": "2b4c1e1f-07c6-4e3d-ad74-5bf658b913f2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "from escnn import gspaces, nn\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from neuralyze import get_hessian_max_spectrum\n",
    "from torch import Tensor, optim, utils\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics import MaxMetric, MeanMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "# from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    InterpolationMode,\n",
    "    Pad,\n",
    "    RandomRotation,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "from src.data.rotated_mnist_datamodule import MnistRotDataset\n",
    "from src.models.image_module import ImageLightningModule\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeDSARcAfAqE"
   },
   "source": [
    "###write lightning module def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNRg68oPfDQa"
   },
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class PlModule(L.LightningModule):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.net = net\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # num classes\n",
    "        num_classes = 10  # net.layers[-1].out_features #if this break hardcode to one\n",
    "\n",
    "        # metric objects for calculating and averaging accuracy across batches\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "        self.train_loss = MeanMetric()\n",
    "        self.val_loss = MeanMetric()\n",
    "        self.test_loss = MeanMetric()\n",
    "\n",
    "        # for averaging loss across batches\n",
    "        self.train_acc_mean = MeanMetric()\n",
    "        self.val_acc_mean = MeanMetric()\n",
    "        self.test_acc_mean = MeanMetric()\n",
    "\n",
    "        # for tracking best so far validation accuracy\n",
    "        self.val_acc_best = MaxMetric()\n",
    "\n",
    "    def model_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Perform a single model step on a batch of data.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target labels.\n",
    "\n",
    "        :return: A tuple containing (in order):\n",
    "            - A tensor of losses.\n",
    "            - A tensor of predictions.\n",
    "            - A tensor of target labels.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.net(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        return loss, preds, y\n",
    "\n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n",
    "        \"\"\"Perform a single test step on a batch of data from the test set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        # print(batch_index)\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        self.test_loss(loss)\n",
    "        self.test_acc_mean(self.test_acc(preds, targets))\n",
    "        self.log(\"test/loss\", self.test_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/acc\", self.test_acc_mean, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n",
    "        \"\"\"Perform a single validation step on a batch of data from the validation set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        self.val_loss(loss)\n",
    "        self.val_acc_mean(self.val_acc(preds, targets))\n",
    "\n",
    "        self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/acc\", self.val_acc_mean, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.val_acc_mean.reset()\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Perform a single training step on a batch of data from the training set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        :return: A tensor of losses between model predictions and targets.\n",
    "        \"\"\"\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        self.train_loss(loss)\n",
    "        self.train_acc_mean(self.train_acc(preds, targets))\n",
    "\n",
    "        self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/acc\", self.train_acc_mean, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # return loss or backpropagation will fail\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        \"Lightning hook that is called when a training epoch ends.\"\n",
    "        self.train_acc_mean.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=5e-5, weight_decay=1e-5)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnkiKVW8YBRG"
   },
   "source": [
    "### Write both the model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cx1ae4AhYHtl"
   },
   "outputs": [],
   "source": [
    "class C8SteerableCNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes=10):\n",
    "\n",
    "        super(C8SteerableCNN, self).__init__()\n",
    "        # self.save_hyperparameters()\n",
    "\n",
    "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
    "        self.r2_act = gspaces.rot2dOnR2(N=8)\n",
    "\n",
    "        # the input image is a scalar field, corresponding to the trivial representation\n",
    "        in_type = nn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
    "\n",
    "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
    "        self.input_type = in_type\n",
    "\n",
    "        # convolution 1\n",
    "        # first specify the output type of the convolutional layer\n",
    "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 24 * [self.r2_act.regular_repr])\n",
    "        self.block1 = nn.SequentialModule(\n",
    "            nn.MaskModule(in_type, 29, margin=1),\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "\n",
    "        # convolution 2\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block1.out_type\n",
    "        # the output type of the second convolution layer are 48 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 48 * [self.r2_act.regular_repr])\n",
    "        self.block2 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "        self.pool1 = nn.SequentialModule(\n",
    "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolution 3\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block2.out_type\n",
    "        # the output type of the third convolution layer are 48 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 48 * [self.r2_act.regular_repr])\n",
    "        self.block3 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "\n",
    "        # convolution 4\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block3.out_type\n",
    "        # the output type of the fourth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 96 * [self.r2_act.regular_repr])\n",
    "        self.block4 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "        self.pool2 = nn.SequentialModule(\n",
    "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolution 5\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block4.out_type\n",
    "        # the output type of the fifth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 96 * [self.r2_act.regular_repr])\n",
    "        self.block5 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "\n",
    "        # convolution 6\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block5.out_type\n",
    "        # the output type of the sixth convolution layer are 64 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 64 * [self.r2_act.regular_repr])\n",
    "        self.block6 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "        self.pool3 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
    "\n",
    "        self.gpool = nn.GroupPooling(out_type)\n",
    "\n",
    "        # number of output channels\n",
    "        c = self.gpool.out_type.size\n",
    "\n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(c, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # wrap the input tensor in a GeometricTensor\n",
    "        # (associate it with the input type)\n",
    "        x = nn.GeometricTensor(input, self.input_type)\n",
    "\n",
    "        # apply each equivariant block\n",
    "\n",
    "        # Each layer has an input and an output type\n",
    "        # A layer takes a GeometricTensor in input.\n",
    "        # This tensor needs to be associated with the same representation of the layer's input type\n",
    "        #\n",
    "        # The Layer outputs a new GeometricTensor, associated with the layer's output type.\n",
    "        # As a result, consecutive layers need to have matching input/output types\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "\n",
    "        # pool over the spatial dimensions\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # pool over the group\n",
    "        x = self.gpool(x)\n",
    "\n",
    "        # unwrap the output GeometricTensor\n",
    "        # (take the Pytorch tensor and discard the associated representation)\n",
    "        x = x.tensor\n",
    "\n",
    "        # classify with the final fully connected layers)\n",
    "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtRsXI3ccT2P"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# V2\n",
    "\n",
    "\n",
    "class BasicInvertedBottleneckBlockV2(torch.nn.Module):\n",
    "    def __init__(self, Cin, N, Cout, downsample=False, first_block=False):\n",
    "        super(BasicInvertedBottleneckBlockV2, self).__init__()\n",
    "\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "\n",
    "        if first_block:\n",
    "            kernel_size = 7\n",
    "            padding = 3\n",
    "\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(Cin, N, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(N),  # idk which BN to use\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            # dit is de enige logische interpretatie van appendix H4 die ik kan bedenken. of miss dit of downsample maar nooit beide? dat is denk ik logischer\n",
    "            # torch.nn.Conv2d(N, Cout, kernel_size=kernel_size, stride=1, padding=padding)\n",
    "        )\n",
    "\n",
    "        self.one_by_one: bool = Cin != Cout\n",
    "\n",
    "        if self.one_by_one:\n",
    "            self.conv1x1 = torch.nn.Conv2d(Cin, Cout, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            # for this one I'm guessing\n",
    "            self.second_conv = torch.nn.Conv2d(\n",
    "                N, Cin, kernel_size=kernel_size, stride=2, padding=padding\n",
    "            )\n",
    "            self.avg_pool = torch.nn.AvgPool2d(kernel_size=kernel_size, stride=2, padding=padding)\n",
    "        else:\n",
    "            self.second_conv = torch.nn.Conv2d(\n",
    "                N, Cin, kernel_size=kernel_size, stride=1, padding=padding\n",
    "            )  # idk setting kernel size to one here does massively reduce the number of parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        # N Channels\n",
    "        # print('before downsample')\n",
    "        # print(out.shape)\n",
    "        # print(x.shape)\n",
    "\n",
    "        out = self.second_conv(out)\n",
    "        # C_in Channels\n",
    "\n",
    "        if self.downsample:\n",
    "            # if the second convolution downsamples\n",
    "            # then the size of the image changes\n",
    "            # so we must decrease x in size\n",
    "            # to be able to add it up\n",
    "            x = self.avg_pool(x)\n",
    "\n",
    "        # print('afterdownsample')\n",
    "        # print(out.shape)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # print('afteronebyone')\n",
    "        # print(out.shape)\n",
    "        # print(x.shape)\n",
    "        skip_connection = out + x\n",
    "        if self.one_by_one:\n",
    "            skip_connection = self.conv1x1(skip_connection)\n",
    "            # C_out\n",
    "\n",
    "        return skip_connection\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, backbone_channels, residual_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.backbone_channels = backbone_channels\n",
    "        self.residual_channels = residual_channels\n",
    "        self.blocks = self._make_blocks()\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "\n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "\n",
    "    def _make_blocks(self):\n",
    "        blocks = []\n",
    "        for i in range(len(self.backbone_channels)):\n",
    "            Cin = self.backbone_channels[i]\n",
    "            N = self.residual_channels[i]\n",
    "            # this next part is because their explanation doesnt seem to include the channel output size of the last block. So we set it to be the same as the input\n",
    "            if i < len(self.backbone_channels) - 1:\n",
    "                Cout = self.backbone_channels[i + 1]\n",
    "            else:\n",
    "                Cout = 32  # this is also very vague from the og paper\n",
    "\n",
    "            # print('hello', i)\n",
    "            if i == 0:\n",
    "                # print('i = 0 -------------------------')\n",
    "                blocks.append(BasicInvertedBottleneckBlockV2(Cin, N, Cout, first_block=True))\n",
    "\n",
    "            elif (i + 1) % 2 == 0:  # every two layers this is true\n",
    "                # print('True-------------------------------------------------------------')\n",
    "                blocks.append(BasicInvertedBottleneckBlockV2(Cin, N, Cout, downsample=True))\n",
    "\n",
    "            else:\n",
    "                # print('normal case =======================')\n",
    "                blocks.append(BasicInvertedBottleneckBlockV2(Cin, N, Cout))\n",
    "        return torch.nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.blocks(x)\n",
    "        out = self.max_pool(out)\n",
    "        # print(out.shape)\n",
    "        out = self.fully_net(out.flatten(start_dim=1))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "backbone_channels = [1, 21, 54, 72, 108, 168]  # These are the C_in's\n",
    "residual_channels = [96, 192, 288, 288, 576, 576]  # These are the upsampled N's\n",
    "cnn_model = CNN(backbone_channels, residual_channels, n_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkQlvjRH0M-n"
   },
   "source": [
    "#### Plot fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpqNlrjZ0MeH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JH8XLDAaSyFm"
   },
   "source": [
    "### C8 steerable hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "abaeaf843e9f415e9ae89c9a525e1a68",
      "783c972688ef4130b04c7b4cd7f2e423",
      "42bb03a6ae954b16a789b015b32863d1",
      "f362c72adf184c0994e1439facaf1355",
      "d9a41c90dba24fad8594b37d99c7f15b",
      "d0aaa5ba63604f93a401d7ac1c5f18e7",
      "831a2229161a4387816b4954d612700a",
      "e9d60988c6da4aeea2ef22307cbb367d"
     ]
    },
    "id": "ZW14BH0mSt3s",
    "outputId": "b442f538-0c79-4141-e7c1-a8fd22bb817c"
   },
   "outputs": [],
   "source": [
    "run = wandb.init()\n",
    "checkpoints = []\n",
    "\n",
    "# put the 15 checkpoints in a list\n",
    "for i in range(15):\n",
    "    checkpoint = run.use_artifact(\n",
    "        \"uva-dl2/C8steerable_RotMNIST/model-u3vh8ed9:v\" + str(i), type=\"model\"\n",
    "    )\n",
    "    dir = checkpoint.download()\n",
    "    checkpoints.append(torch.load(dir + \"/model.ckpt\"))\n",
    "\n",
    "# finish wandb\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwW_ieeF1iY4",
    "outputId": "42c1abc7-f254-436c-9d19-ce335c5e1285"
   },
   "outputs": [],
   "source": [
    "model = C8SteerableCNN().to(device)\n",
    "equivariantmodel = PlModule(model)\n",
    "equivariantmodel.load_state_dict(checkpoints[1][\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rneHVGoSXlTF",
    "outputId": "d0da7e46-d638-4fad-dc85-31db9f1d191d"
   },
   "outputs": [],
   "source": [
    "print(len(checkpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0sqsAWcj4aG"
   },
   "outputs": [],
   "source": [
    "# get dataloader\n",
    "# define transforms\n",
    "pad = Pad((0, 0, 1, 1), fill=0)\n",
    "\n",
    "resize1 = Resize(87)\n",
    "resize2 = Resize(29)\n",
    "\n",
    "totensor = ToTensor()\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        pad,\n",
    "        resize1,\n",
    "        RandomRotation(180.0, interpolation=InterpolationMode.BILINEAR, expand=False),\n",
    "        resize2,\n",
    "        totensor,\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = Compose(\n",
    "    [\n",
    "        pad,\n",
    "        totensor,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "dataset = MnistRotDataset(\"data/mnist/\", download=True, transform=train_transform)\n",
    "train_loader1 = utils.data.DataLoader(dataset, batch_size=64, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857,
     "referenced_widgets": [
      "e2724204fe7845c8a03821236956751e",
      "414f2270c00146a3a8e80dd5269558eb",
      "f432cd44954c45a487dd14d4b1681a5f",
      "ebc3b40dd7054193ae80c4c51a7df8af",
      "401a7c7fea0e4e9cb8b1f077cb10d40c",
      "5e410c31c5b84e908c9dff76999b343b",
      "4e3cbdb02ec64d69b63a924794f23475",
      "012190a4e8d94823be3b2db24488567c",
      "50eb8b4c40b94f1ebd035c0066785afd",
      "e8d1fd15b9144251bacd2fcb86472872",
      "d43ed4fd2d4b41dc9d674d526af0fc65",
      "3adeec7eaab2477aa0d8156af06a6066",
      "d749eeafabf149438bf52bc2a6b65cf4",
      "e329b80e594f470688278f106f4a4f4e",
      "08d8a518214a4cd9b10a99476de79018",
      "0e153a70d9e446d5bd08b7f11b0283c4",
      "c605136358384a968787bbd3b21bf9af",
      "fd29df31f350422bac7a36e9d501223f",
      "d03714a551bf437dba90563630931e03",
      "c961248655dc414c8f5b9a55d63a4d70",
      "69ef75c79f1d4be8a7ee227437dd6c37",
      "1437a6540e0443539e7124460bfe12bd",
      "42747c6def384c51a7e7adf1e08f666b",
      "06ec982bc8654ea887c43ee12062cb67",
      "f3c5198d65d34d13bffce1658b0ae4e2",
      "b3aa8fb1a785417097e6d257a2b6518a",
      "cedb3e2543544c7aba992af0aa692a73",
      "5570de687db14db49c517f0d199c6fc8",
      "f08a42d745ae4e9bb2e4e1990076f9a9",
      "a7bac047478c421db7c4a64deec7383c",
      "00992e24a71543d582b3ade557e1eda8",
      "aac9c92309fd433d90c7451789d86866",
      "f562aa63b0c143b8b742c503bd7eea71"
     ]
    },
    "id": "27ar7YS7Ulo9",
    "outputId": "5b2a5d37-ac28-4d9e-c321-362598664654"
   },
   "outputs": [],
   "source": [
    "## evaluate the test set at the checkpoints\n",
    "test_transform = Compose(\n",
    "    [\n",
    "        pad,\n",
    "        totensor,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = MnistRotDataset(\n",
    "    \"data/mnist/\", download=False, train=False, transform=test_transform\n",
    ")\n",
    "\n",
    "test_loader = utils.data.DataLoader(test_dataset, batch_size=64, num_workers=7)\n",
    "\n",
    "trainer = L.Trainer()\n",
    "for checkpoint in checkpoints:\n",
    "    equivariantmodel = PlModule(model)\n",
    "    equivariantmodel.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    trainer.test(model=equivariantmodel, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3YI0TxybOz1",
    "outputId": "48a45b2a-edaf-4c2f-bd05-4ec79ac115c9"
   },
   "outputs": [],
   "source": [
    "# get criterion\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "weight_decay = 1e-5\n",
    "top_k = 1\n",
    "\n",
    "spectrum = get_hessian_max_spectrum(\n",
    "    model=equivariantmodel.net,\n",
    "    criterion=loss_fn,\n",
    "    train_dataloader=train_loader1,\n",
    "    weight_decay=weight_decay,\n",
    "    top_k=top_k,\n",
    "    cuda=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# plotting etc...\n",
    "print(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "dyDj4iiKyt53",
    "outputId": "1b91b574-109c-49e5-a2a7-9e711a8e50b9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "print(sum(np.array(spectrum) < 0))\n",
    "\n",
    "# Create kernel density estimate\n",
    "kde = gaussian_kde(spectrum)\n",
    "\n",
    "# Create x values for the plot\n",
    "x = np.linspace(min(spectrum), max(spectrum), 1000)\n",
    "\n",
    "# Compute the density estimate\n",
    "density = kde(x)\n",
    "\n",
    "# Plot density estimate as a line\n",
    "plt.plot(x, density)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wGdspQEbdKu"
   },
   "source": [
    "###Do for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452,
     "referenced_widgets": [
      "6f6d73ebec9141eda7253fc51398ba75",
      "e6072013f648409e9499900d6607dfc3",
      "59d9807d546a416f8c67c868cc6ff7ea",
      "a6c219dfe49841e0860d3a000dfdcc07",
      "d6367f21b2034f76ae8e4649a9c50939",
      "1704fff76dce4328a513e03d902efa9b",
      "05968dfcea1e4429b6900c053155588d",
      "56a3e18d584e4221a4cd8ce07fc15dab"
     ]
    },
    "id": "lf5tUlwAbv1k",
    "outputId": "72da0c83-0618-4341-ade6-7460fd442814"
   },
   "outputs": [],
   "source": [
    "run = wandb.init()\n",
    "cnn_checkpoints = []\n",
    "\n",
    "# put the 15 checkpoints in a list\n",
    "for i in range(15):\n",
    "    checkpoint = run.use_artifact(\"uva-dl2/CNN_RotMNIST/model-4l530hst:v\" + str(i), type=\"model\")\n",
    "    dir = checkpoint.download()\n",
    "    cnn_checkpoints.append(torch.load(dir + \"/model.ckpt\"))\n",
    "\n",
    "\n",
    "# finish wandb run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4dibe2Mbzmg",
    "outputId": "6ce117c9-b8a8-41b7-f225-5b821c57704d"
   },
   "outputs": [],
   "source": [
    "print(len(cnn_checkpoints))\n",
    "cnn = PlModule(cnn_model)\n",
    "cnn.load_state_dict(cnn_checkpoints[12][\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxDAuPSnb7W2"
   },
   "outputs": [],
   "source": [
    "pad = Pad((0, 0, 1, 1), fill=0)\n",
    "\n",
    "resize1 = Resize(87)\n",
    "resize2 = Resize(29)\n",
    "\n",
    "totensor = ToTensor()\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        pad,\n",
    "        resize1,\n",
    "        RandomRotation(180.0, interpolation=InterpolationMode.BILINEAR, expand=False),\n",
    "        resize2,\n",
    "        totensor,\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = Compose(\n",
    "    [\n",
    "        pad,\n",
    "        totensor,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "dataset = MnistRotDataset(\"data/mnist/\", download=True, transform=train_transform)\n",
    "train_loader1 = utils.data.DataLoader(dataset, batch_size=64, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDluPFKqbilc",
    "outputId": "18ba8198-74b8-4bc3-ec2a-114efddcbd84"
   },
   "outputs": [],
   "source": [
    "# get criterion\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "weight_decay = 1e-5\n",
    "top_k = 1\n",
    "\n",
    "spectrum = get_hessian_max_spectrum(\n",
    "    model=cnn.net,\n",
    "    criterion=loss_fn,\n",
    "    train_dataloader=train_loader1,\n",
    "    weight_decay=weight_decay,\n",
    "    top_k=top_k,\n",
    "    cuda=True,\n",
    "    verbose=False,\n",
    ")\n",
    "# plotting etc...\n",
    "print(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "407PEi5ofYks",
    "outputId": "269429e4-fa4f-4a0d-cfa4-fdccd249a9fe"
   },
   "outputs": [],
   "source": [
    "print(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "rYMC7_YnfbMW",
    "outputId": "b4d38fc7-768b-4001-8913-b628dab21498"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "print(sum(np.array(spectrum) < 0))\n",
    "\n",
    "# Create kernel density estimate\n",
    "kde = gaussian_kde(spectrum)\n",
    "\n",
    "# Create x values for the plot\n",
    "x = np.linspace(min(spectrum), max(spectrum), 1000)\n",
    "\n",
    "# Compute the density estimate\n",
    "density = kde(x)\n",
    "\n",
    "# Plot density estimate as a line\n",
    "plt.plot(x, density)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VXZrftn4ESH"
   },
   "source": [
    "###put everything in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSG-GYs86A4O"
   },
   "outputs": [],
   "source": [
    "def plot_fn(spectrums: list, names: list, epoch: int):\n",
    "    fig, ax = plt.subplots()\n",
    "    # Create kernel density estimate\n",
    "    for spectrum, name in zip(spectrums, names):\n",
    "        kde = gaussian_kde(spectrum)\n",
    "\n",
    "        # Create x values for the plot\n",
    "        x = np.linspace(min(spectrum), max(spectrum), 1000)\n",
    "\n",
    "        # Compute the density estimate\n",
    "        density = kde(x)\n",
    "\n",
    "        # Plot density estimate as a line\n",
    "        ax.plot(x, density, label=name)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel(\"Max Eigenvalue\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(\"Density plot of max eigenvalues at epoch \" + str(epoch))\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "pqlCG24g44mP",
    "outputId": "15f4e59a-e1aa-4361-bb43-747b98b2ce41"
   },
   "outputs": [],
   "source": [
    "cnn_epoch2 = [\n",
    "    6875.40625,\n",
    "    5458.1083984375,\n",
    "    4423.2001953125,\n",
    "    4683.611328125,\n",
    "    5941.65283203125,\n",
    "    4858.1328125,\n",
    "    4823.703125,\n",
    "    5896.98828125,\n",
    "    5852.12109375,\n",
    "    5031.59228515625,\n",
    "    5160.06298828125,\n",
    "    4729.49462890625,\n",
    "    4687.4990234375,\n",
    "    8037.125,\n",
    "    5394.51513671875,\n",
    "    4012.002685546875,\n",
    "    5615.88818359375,\n",
    "    6808.6826171875,\n",
    "    6529.435546875,\n",
    "    5828.2626953125,\n",
    "    6375.70263671875,\n",
    "    6066.27734375,\n",
    "    3965.632568359375,\n",
    "    4112.02783203125,\n",
    "    6158.7685546875,\n",
    "    6011.3955078125,\n",
    "    5706.56689453125,\n",
    "    4558.5634765625,\n",
    "    4919.46875,\n",
    "    4116.5576171875,\n",
    "    5973.62158203125,\n",
    "    4209.6865234375,\n",
    "    7843.30224609375,\n",
    "    5642.18896484375,\n",
    "    6206.28515625,\n",
    "    5202.30810546875,\n",
    "    7452.43408203125,\n",
    "    5710.0068359375,\n",
    "    7445.5595703125,\n",
    "    4984.33203125,\n",
    "    8024.2041015625,\n",
    "    7435.71826171875,\n",
    "    6818.78564453125,\n",
    "    6401.49365234375,\n",
    "    5641.6650390625,\n",
    "    7815.703125,\n",
    "    4988.9267578125,\n",
    "    6618.49169921875,\n",
    "    5833.705078125,\n",
    "    5644.5712890625,\n",
    "    7210.99267578125,\n",
    "    6100.619140625,\n",
    "    7903.171875,\n",
    "    5609.67724609375,\n",
    "    9615.8232421875,\n",
    "    5828.18701171875,\n",
    "    3833.476318359375,\n",
    "    7533.93701171875,\n",
    "    6343.1982421875,\n",
    "    5757.0361328125,\n",
    "    5240.94384765625,\n",
    "    7500.3837890625,\n",
    "    8404.8544921875,\n",
    "    6103.01123046875,\n",
    "    5035.01416015625,\n",
    "    5455.63916015625,\n",
    "    5202.40966796875,\n",
    "    4872.60546875,\n",
    "    5992.033203125,\n",
    "    9025.474609375,\n",
    "    4555.62060546875,\n",
    "    6732.37646484375,\n",
    "    6664.4228515625,\n",
    "    8437.919921875,\n",
    "    8140.16064453125,\n",
    "    4803.15380859375,\n",
    "    5537.908203125,\n",
    "    7520.40966796875,\n",
    "    9194.26171875,\n",
    "    6405.05615234375,\n",
    "    5738.361328125,\n",
    "    4769.97705078125,\n",
    "    7116.65087890625,\n",
    "    4839.0634765625,\n",
    "    5039.64306640625,\n",
    "    5679.08447265625,\n",
    "    5501.91162109375,\n",
    "    6773.61083984375,\n",
    "    7073.40234375,\n",
    "    6215.61767578125,\n",
    "    12549.6103515625,\n",
    "    5246.15087890625,\n",
    "    4800.44873046875,\n",
    "    2576.76611328125,\n",
    "    4823.91015625,\n",
    "    8342.9296875,\n",
    "    5892.50390625,\n",
    "    6700.95361328125,\n",
    "    4060.697265625,\n",
    "    5781.48388671875,\n",
    "    5207.65771484375,\n",
    "    7800.92822265625,\n",
    "    5595.53857421875,\n",
    "    6312.095703125,\n",
    "    5106.3603515625,\n",
    "    7603.74951171875,\n",
    "    5499.97509765625,\n",
    "    4950.3359375,\n",
    "    5303.32373046875,\n",
    "    5097.0166015625,\n",
    "    5528.58154296875,\n",
    "    5350.11083984375,\n",
    "    5879.474609375,\n",
    "    5749.6787109375,\n",
    "    4464.69091796875,\n",
    "    4241.6728515625,\n",
    "    3762.043701171875,\n",
    "    4796.3291015625,\n",
    "    4872.37255859375,\n",
    "    6653.833984375,\n",
    "    7951.5654296875,\n",
    "    4945.408203125,\n",
    "    4874.1982421875,\n",
    "    5586.96630859375,\n",
    "    6442.841796875,\n",
    "    7207.982421875,\n",
    "    6233.39599609375,\n",
    "    6085.5615234375,\n",
    "    7803.0146484375,\n",
    "    5554.30126953125,\n",
    "    5043.337890625,\n",
    "    6850.36767578125,\n",
    "    4261.89794921875,\n",
    "    5584.1748046875,\n",
    "    6318.6123046875,\n",
    "    7457.54296875,\n",
    "    5151.49951171875,\n",
    "    6157.54931640625,\n",
    "    7693.1611328125,\n",
    "    6201.69482421875,\n",
    "    4867.462890625,\n",
    "    8440.51171875,\n",
    "    4419.93408203125,\n",
    "    4183.197265625,\n",
    "    4575.37548828125,\n",
    "    7047.0185546875,\n",
    "    7283.37451171875,\n",
    "    5314.14794921875,\n",
    "    5808.33154296875,\n",
    "    5411.41796875,\n",
    "    5687.88525390625,\n",
    "    6820.060546875,\n",
    "    6485.29638671875,\n",
    "    7957.88671875,\n",
    "    6337.58447265625,\n",
    "    4017.68798828125,\n",
    "    6778.3818359375,\n",
    "    5335.61279296875,\n",
    "    7552.31689453125,\n",
    "    7063.775390625,\n",
    "    7346.70849609375,\n",
    "    5066.396484375,\n",
    "    4531.8134765625,\n",
    "    4710.28173828125,\n",
    "    6924.7734375,\n",
    "    7473.9931640625,\n",
    "    5783.69921875,\n",
    "    7789.40283203125,\n",
    "    4608.96875,\n",
    "    6278.18408203125,\n",
    "    5102.08056640625,\n",
    "    7899.7890625,\n",
    "    5188.20458984375,\n",
    "    6280.3212890625,\n",
    "    6939.212890625,\n",
    "    6125.77197265625,\n",
    "    6051.2744140625,\n",
    "    5465.64013671875,\n",
    "    7250.2724609375,\n",
    "    4638.0947265625,\n",
    "    6418.1240234375,\n",
    "    5552.11962890625,\n",
    "    8209.287109375,\n",
    "    5717.70654296875,\n",
    "    8915.33984375,\n",
    "    8058.36962890625,\n",
    "    6196.37109375,\n",
    "    4062.49560546875,\n",
    "]\n",
    "cnn_epoch24 = [\n",
    "    2275.118408203125,\n",
    "    1095.6337890625,\n",
    "    1039.4385986328125,\n",
    "    2222.73876953125,\n",
    "    1411.3935546875,\n",
    "    875.824951171875,\n",
    "    1904.9405517578125,\n",
    "    1949.60791015625,\n",
    "    2553.19970703125,\n",
    "    1305.8563232421875,\n",
    "    1030.135986328125,\n",
    "    1272.5654296875,\n",
    "    1916.4949951171875,\n",
    "    1468.9964599609375,\n",
    "    895.3472900390625,\n",
    "    1440.815185546875,\n",
    "    1127.07666015625,\n",
    "    1392.247802734375,\n",
    "    2330.771728515625,\n",
    "    608.7413330078125,\n",
    "    2996.583740234375,\n",
    "    3431.375732421875,\n",
    "    1156.906494140625,\n",
    "    898.31689453125,\n",
    "    1904.0301513671875,\n",
    "    2993.462890625,\n",
    "    1316.552001953125,\n",
    "    1383.8214111328125,\n",
    "    2872.70947265625,\n",
    "    2868.049560546875,\n",
    "    1806.08154296875,\n",
    "    729.8719482421875,\n",
    "    1321.500732421875,\n",
    "    1907.0887451171875,\n",
    "    1626.5419921875,\n",
    "    1356.6319580078125,\n",
    "    2472.715087890625,\n",
    "    1448.74658203125,\n",
    "    1383.6541748046875,\n",
    "    1575.610107421875,\n",
    "    2452.189697265625,\n",
    "    2792.68994140625,\n",
    "    2271.71142578125,\n",
    "    1328.8927001953125,\n",
    "    1576.3148193359375,\n",
    "    2436.5751953125,\n",
    "    1139.0185546875,\n",
    "    1186.6630859375,\n",
    "    4752.67431640625,\n",
    "    1992.92431640625,\n",
    "    2231.489013671875,\n",
    "    1201.863525390625,\n",
    "    741.259765625,\n",
    "    1332.9908447265625,\n",
    "    2264.212646484375,\n",
    "    4296.353515625,\n",
    "    775.919189453125,\n",
    "    2617.020751953125,\n",
    "    1475.970458984375,\n",
    "    1383.945556640625,\n",
    "    2079.74267578125,\n",
    "    987.4376831054688,\n",
    "    1174.7044677734375,\n",
    "    1706.98388671875,\n",
    "    1339.1964111328125,\n",
    "    1763.966064453125,\n",
    "    1365.6197509765625,\n",
    "    1363.8260498046875,\n",
    "    2337.251708984375,\n",
    "    1142.4588623046875,\n",
    "    856.9503784179688,\n",
    "    2870.81689453125,\n",
    "    5025.41015625,\n",
    "    2484.961669921875,\n",
    "    1460.8349609375,\n",
    "    1588.71875,\n",
    "    1029.816162109375,\n",
    "    1856.9176025390625,\n",
    "    1057.73974609375,\n",
    "    2549.375732421875,\n",
    "    969.8262939453125,\n",
    "    1673.4315185546875,\n",
    "    2536.720947265625,\n",
    "    1189.735595703125,\n",
    "    842.6403198242188,\n",
    "    1157.396240234375,\n",
    "    1539.49609375,\n",
    "    1925.9476318359375,\n",
    "    956.359130859375,\n",
    "    2393.259033203125,\n",
    "    2308.452880859375,\n",
    "    1346.31787109375,\n",
    "    1953.202880859375,\n",
    "    2076.034423828125,\n",
    "    1388.024658203125,\n",
    "    2606.22265625,\n",
    "    2092.852294921875,\n",
    "    1794.3182373046875,\n",
    "    910.8128051757812,\n",
    "    2985.702392578125,\n",
    "    1121.739990234375,\n",
    "    3338.694580078125,\n",
    "    1385.4969482421875,\n",
    "    1475.760498046875,\n",
    "    1523.9459228515625,\n",
    "    2316.929443359375,\n",
    "    1666.53466796875,\n",
    "    1805.6136474609375,\n",
    "    1798.634033203125,\n",
    "    1436.483154296875,\n",
    "    1543.68798828125,\n",
    "    1779.47998046875,\n",
    "    1579.802001953125,\n",
    "    1751.056884765625,\n",
    "    1636.9447021484375,\n",
    "    1938.5516357421875,\n",
    "    1515.407958984375,\n",
    "    1292.427001953125,\n",
    "    2660.054443359375,\n",
    "    2108.15673828125,\n",
    "    2486.980224609375,\n",
    "    1794.8109130859375,\n",
    "    2224.41796875,\n",
    "    2105.936767578125,\n",
    "    2384.95166015625,\n",
    "    3319.75,\n",
    "    1595.4737548828125,\n",
    "    2444.44775390625,\n",
    "    1833.89013671875,\n",
    "    1174.57470703125,\n",
    "    2652.756103515625,\n",
    "    2328.857177734375,\n",
    "    1845.059326171875,\n",
    "    2665.083740234375,\n",
    "    4761.80810546875,\n",
    "    1819.90087890625,\n",
    "    2244.44580078125,\n",
    "    2171.89794921875,\n",
    "    2436.1630859375,\n",
    "    1565.2130126953125,\n",
    "    2296.580810546875,\n",
    "    2446.5986328125,\n",
    "    1551.7867431640625,\n",
    "    2382.902587890625,\n",
    "    1773.6556396484375,\n",
    "    2630.6806640625,\n",
    "    1756.77734375,\n",
    "    1127.5264892578125,\n",
    "    2086.9296875,\n",
    "    1598.426513671875,\n",
    "    2118.333984375,\n",
    "    1417.4432373046875,\n",
    "    1391.093017578125,\n",
    "    2123.302490234375,\n",
    "    1912.5367431640625,\n",
    "    1849.6383056640625,\n",
    "    2458.71337890625,\n",
    "    1643.869873046875,\n",
    "    3266.890869140625,\n",
    "    1487.9603271484375,\n",
    "    2364.990234375,\n",
    "    1210.434326171875,\n",
    "    826.3599853515625,\n",
    "    1864.6097412109375,\n",
    "    1405.7088623046875,\n",
    "    1469.961669921875,\n",
    "    1539.8736572265625,\n",
    "    2638.4970703125,\n",
    "    827.0991821289062,\n",
    "    868.0311279296875,\n",
    "    2297.556396484375,\n",
    "    5333.80224609375,\n",
    "    1841.739013671875,\n",
    "    1316.693359375,\n",
    "    3573.09130859375,\n",
    "    2613.081787109375,\n",
    "    1187.273681640625,\n",
    "    1013.5319213867188,\n",
    "    2179.75634765625,\n",
    "    1148.74658203125,\n",
    "    2292.6611328125,\n",
    "    1079.3045654296875,\n",
    "    1223.306884765625,\n",
    "    2630.29296875,\n",
    "    2276.338134765625,\n",
    "    1363.71630859375,\n",
    "    1543.708984375,\n",
    "    1406.6788330078125,\n",
    "]\n",
    "\n",
    "scnn_epoch2 = [\n",
    "    333.031982421875,\n",
    "    254.37513732910156,\n",
    "    395.8107604980469,\n",
    "    287.7648010253906,\n",
    "    401.6199951171875,\n",
    "    414.1491394042969,\n",
    "    410.441162109375,\n",
    "    498.984619140625,\n",
    "    530.0369262695312,\n",
    "    296.0187072753906,\n",
    "    387.8148498535156,\n",
    "    274.1049499511719,\n",
    "    766.5582885742188,\n",
    "    465.79052734375,\n",
    "    422.53411865234375,\n",
    "    417.55615234375,\n",
    "    403.8988952636719,\n",
    "    532.3838500976562,\n",
    "    720.0921630859375,\n",
    "    479.35028076171875,\n",
    "    528.6215209960938,\n",
    "    454.8970947265625,\n",
    "    397.3937683105469,\n",
    "    409.3011474609375,\n",
    "    329.2708435058594,\n",
    "    510.29620361328125,\n",
    "    758.2106323242188,\n",
    "    740.628662109375,\n",
    "    572.430419921875,\n",
    "    692.5631103515625,\n",
    "    520.3715209960938,\n",
    "    182.6204833984375,\n",
    "    590.7817993164062,\n",
    "    523.0174560546875,\n",
    "    613.02099609375,\n",
    "    503.0660400390625,\n",
    "    579.7132568359375,\n",
    "    490.16015625,\n",
    "    331.343994140625,\n",
    "    418.6534118652344,\n",
    "    438.0970458984375,\n",
    "    506.46990966796875,\n",
    "    538.7897338867188,\n",
    "    290.7578430175781,\n",
    "    413.21563720703125,\n",
    "    481.84820556640625,\n",
    "    541.3834838867188,\n",
    "    677.215576171875,\n",
    "    747.4902954101562,\n",
    "    467.7528076171875,\n",
    "    739.9113159179688,\n",
    "    560.5393676757812,\n",
    "    512.3710327148438,\n",
    "    303.5492248535156,\n",
    "    610.9276123046875,\n",
    "    316.61871337890625,\n",
    "    221.5895233154297,\n",
    "    362.7914733886719,\n",
    "    313.8654479980469,\n",
    "    872.2951049804688,\n",
    "    458.436279296875,\n",
    "    263.7212219238281,\n",
    "    484.5103454589844,\n",
    "    399.1614685058594,\n",
    "    738.9041748046875,\n",
    "    272.5138244628906,\n",
    "    458.6981201171875,\n",
    "    303.18414306640625,\n",
    "    393.77984619140625,\n",
    "    328.2042541503906,\n",
    "    413.8892822265625,\n",
    "    642.6610717773438,\n",
    "    641.008544921875,\n",
    "    874.1571655273438,\n",
    "    372.827392578125,\n",
    "    529.0104370117188,\n",
    "    268.7242736816406,\n",
    "    481.32318115234375,\n",
    "    482.2596130371094,\n",
    "    510.3630065917969,\n",
    "    427.1429748535156,\n",
    "    433.3789978027344,\n",
    "    408.65167236328125,\n",
    "    223.23452758789062,\n",
    "    231.7783203125,\n",
    "    491.7130126953125,\n",
    "    443.9861145019531,\n",
    "    483.562255859375,\n",
    "    264.6827087402344,\n",
    "    370.2630615234375,\n",
    "    292.4689636230469,\n",
    "    261.6284484863281,\n",
    "    372.6754455566406,\n",
    "    557.0153198242188,\n",
    "    802.7447509765625,\n",
    "    423.7261047363281,\n",
    "    359.6263122558594,\n",
    "    329.3255310058594,\n",
    "    515.5411376953125,\n",
    "    511.0309143066406,\n",
    "    198.85968017578125,\n",
    "    303.0186462402344,\n",
    "    411.8247375488281,\n",
    "    729.6478881835938,\n",
    "    412.2502136230469,\n",
    "    336.8749084472656,\n",
    "    726.7825927734375,\n",
    "    622.3912963867188,\n",
    "    484.619384765625,\n",
    "    269.9864807128906,\n",
    "    386.95208740234375,\n",
    "    552.688232421875,\n",
    "    477.0025634765625,\n",
    "    511.48223876953125,\n",
    "    429.30340576171875,\n",
    "    257.7005615234375,\n",
    "    347.59210205078125,\n",
    "    307.7939147949219,\n",
    "    592.5737915039062,\n",
    "    657.2743530273438,\n",
    "    601.2853393554688,\n",
    "    247.1113739013672,\n",
    "    334.7955627441406,\n",
    "    576.3949584960938,\n",
    "    588.1029663085938,\n",
    "    529.8814697265625,\n",
    "    365.58721923828125,\n",
    "    571.9590454101562,\n",
    "    476.028564453125,\n",
    "    335.2339782714844,\n",
    "    471.9889831542969,\n",
    "    770.2286987304688,\n",
    "    665.1209716796875,\n",
    "    565.0595703125,\n",
    "    822.701171875,\n",
    "    531.0625,\n",
    "    973.8545532226562,\n",
    "    410.9610595703125,\n",
    "    789.7733154296875,\n",
    "    537.3961791992188,\n",
    "    452.2750244140625,\n",
    "    544.9236450195312,\n",
    "    328.4250183105469,\n",
    "    430.4637451171875,\n",
    "    573.8278198242188,\n",
    "    355.9228515625,\n",
    "    441.9842529296875,\n",
    "    378.67327880859375,\n",
    "    444.3838806152344,\n",
    "    477.47955322265625,\n",
    "    556.3922729492188,\n",
    "    315.4058837890625,\n",
    "    495.8985595703125,\n",
    "    368.0945739746094,\n",
    "    419.21917724609375,\n",
    "    579.9761352539062,\n",
    "    332.9350280761719,\n",
    "    502.3441467285156,\n",
    "    336.343505859375,\n",
    "    460.5832214355469,\n",
    "    240.65048217773438,\n",
    "    189.80686950683594,\n",
    "    367.5255126953125,\n",
    "    215.28997802734375,\n",
    "    536.4002075195312,\n",
    "    451.96917724609375,\n",
    "    307.2962646484375,\n",
    "    248.85569763183594,\n",
    "    218.47706604003906,\n",
    "    278.7452087402344,\n",
    "    738.1245727539062,\n",
    "    520.2979125976562,\n",
    "    330.4383850097656,\n",
    "    277.6267395019531,\n",
    "    425.00018310546875,\n",
    "    381.9191589355469,\n",
    "    466.0438232421875,\n",
    "    513.95556640625,\n",
    "    673.2568969726562,\n",
    "    510.0746154785156,\n",
    "    650.2837524414062,\n",
    "    188.16029357910156,\n",
    "    271.6206359863281,\n",
    "    381.33868408203125,\n",
    "    494.6335144042969,\n",
    "    356.8428649902344,\n",
    "    360.6876220703125,\n",
    "    568.6244506835938,\n",
    "]\n",
    "scnn_epoch24 = [\n",
    "    314.642333984375,\n",
    "    173.0394744873047,\n",
    "    251.52407836914062,\n",
    "    224.0927276611328,\n",
    "    289.7452697753906,\n",
    "    518.0335693359375,\n",
    "    70.21331787109375,\n",
    "    133.7662353515625,\n",
    "    174.97073364257812,\n",
    "    242.20401000976562,\n",
    "    75.68696594238281,\n",
    "    141.51077270507812,\n",
    "    211.8843994140625,\n",
    "    254.21253967285156,\n",
    "    408.58538818359375,\n",
    "    347.27166748046875,\n",
    "    231.11448669433594,\n",
    "    70.58531951904297,\n",
    "    200.52410888671875,\n",
    "    253.30239868164062,\n",
    "    142.2261505126953,\n",
    "    507.2702331542969,\n",
    "    374.36279296875,\n",
    "    234.97105407714844,\n",
    "    37.048274993896484,\n",
    "    709.0480346679688,\n",
    "    309.60760498046875,\n",
    "    174.18565368652344,\n",
    "    508.20440673828125,\n",
    "    348.5980224609375,\n",
    "    377.426513671875,\n",
    "    79.34432220458984,\n",
    "    150.40591430664062,\n",
    "    62.91594696044922,\n",
    "    89.2257308959961,\n",
    "    123.99053955078125,\n",
    "    182.80841064453125,\n",
    "    535.4548950195312,\n",
    "    499.47601318359375,\n",
    "    732.4172973632812,\n",
    "    82.8945083618164,\n",
    "    92.45112609863281,\n",
    "    282.131591796875,\n",
    "    86.27645111083984,\n",
    "    75.18305206298828,\n",
    "    413.90423583984375,\n",
    "    114.23973846435547,\n",
    "    889.9210815429688,\n",
    "    318.5820617675781,\n",
    "    586.5587158203125,\n",
    "    450.68701171875,\n",
    "    150.817626953125,\n",
    "    312.25372314453125,\n",
    "    383.4609680175781,\n",
    "    362.8493957519531,\n",
    "    532.34765625,\n",
    "    274.8279724121094,\n",
    "    166.28546142578125,\n",
    "    49.724098205566406,\n",
    "    463.49322509765625,\n",
    "    106.7916488647461,\n",
    "    92.72545623779297,\n",
    "    728.14404296875,\n",
    "    118.90805053710938,\n",
    "    700.1868896484375,\n",
    "    239.196044921875,\n",
    "    181.5623779296875,\n",
    "    512.6734008789062,\n",
    "    586.2227172851562,\n",
    "    267.2084045410156,\n",
    "    200.5968780517578,\n",
    "    56.24433898925781,\n",
    "    85.43285369873047,\n",
    "    151.36549377441406,\n",
    "    141.33209228515625,\n",
    "    480.5205078125,\n",
    "    345.6182861328125,\n",
    "    113.46076965332031,\n",
    "    185.97796630859375,\n",
    "    441.51708984375,\n",
    "    95.9354248046875,\n",
    "    631.320068359375,\n",
    "    676.0302124023438,\n",
    "    36.419639587402344,\n",
    "    175.99636840820312,\n",
    "    91.646484375,\n",
    "    242.6637725830078,\n",
    "    295.6427001953125,\n",
    "    153.91709899902344,\n",
    "    77.33868408203125,\n",
    "    113.58612823486328,\n",
    "    228.50839233398438,\n",
    "    358.5420837402344,\n",
    "    346.5455322265625,\n",
    "    644.94189453125,\n",
    "    139.03628540039062,\n",
    "    179.16546630859375,\n",
    "    314.6929626464844,\n",
    "    171.4453887939453,\n",
    "    116.79743194580078,\n",
    "    109.5234603881836,\n",
    "    311.95220947265625,\n",
    "    155.49615478515625,\n",
    "    911.0560302734375,\n",
    "    303.4095153808594,\n",
    "    201.7030487060547,\n",
    "    619.3152465820312,\n",
    "    158.49351501464844,\n",
    "    103.769775390625,\n",
    "    116.8880615234375,\n",
    "    380.30511474609375,\n",
    "    498.2089538574219,\n",
    "    82.62061309814453,\n",
    "    340.9488830566406,\n",
    "    177.7736053466797,\n",
    "    30.15569305419922,\n",
    "    519.9591064453125,\n",
    "    295.7077331542969,\n",
    "    296.7663269042969,\n",
    "    950.8773193359375,\n",
    "    203.52793884277344,\n",
    "    186.70701599121094,\n",
    "    181.02883911132812,\n",
    "    263.6725158691406,\n",
    "    243.75843811035156,\n",
    "    180.3946990966797,\n",
    "    315.0299072265625,\n",
    "    608.1897583007812,\n",
    "    245.5016326904297,\n",
    "    50.253395080566406,\n",
    "    55.26443099975586,\n",
    "    249.5272979736328,\n",
    "    147.0072479248047,\n",
    "    96.0326156616211,\n",
    "    280.4730529785156,\n",
    "    247.1970977783203,\n",
    "    397.70416259765625,\n",
    "    383.3400573730469,\n",
    "    74.02103424072266,\n",
    "    75.7012939453125,\n",
    "    1144.8358154296875,\n",
    "    102.35597229003906,\n",
    "    193.84149169921875,\n",
    "    82.64066314697266,\n",
    "    97.4927978515625,\n",
    "    142.8053436279297,\n",
    "    137.12156677246094,\n",
    "    372.5215148925781,\n",
    "    322.0830993652344,\n",
    "    448.4815368652344,\n",
    "    188.78372192382812,\n",
    "    239.43112182617188,\n",
    "    59.15226745605469,\n",
    "    330.9130554199219,\n",
    "    134.79830932617188,\n",
    "    230.75701904296875,\n",
    "    44.7327995300293,\n",
    "    84.60397338867188,\n",
    "    56.85826110839844,\n",
    "    44.78538513183594,\n",
    "    199.33502197265625,\n",
    "    33.233089447021484,\n",
    "    384.9004821777344,\n",
    "    68.20487976074219,\n",
    "    51.88193893432617,\n",
    "    198.47805786132812,\n",
    "    60.4770622253418,\n",
    "    55.7204475402832,\n",
    "    56.83805465698242,\n",
    "    28.10547637939453,\n",
    "    367.2054138183594,\n",
    "    262.2610778808594,\n",
    "    45.478084564208984,\n",
    "    134.99961853027344,\n",
    "    83.70127868652344,\n",
    "    127.74578094482422,\n",
    "    327.6318359375,\n",
    "    646.6409301757812,\n",
    "    179.415771484375,\n",
    "    438.2740783691406,\n",
    "    45.22396469116211,\n",
    "    42.39576721191406,\n",
    "    109.94139099121094,\n",
    "    123.7861557006836,\n",
    "    190.0303192138672,\n",
    "    82.54149627685547,\n",
    "    139.28213500976562,\n",
    "    302.4882507324219,\n",
    "]\n",
    "\n",
    "plot_fn([cnn_epoch24, scnn_epoch24], [\"cnn\", \"c8 steerable cnn\"], 24)\n",
    "plot_fn([cnn_epoch2, scnn_epoch2], [\"cnn\", \"c8 steerable cnn\"], 2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
