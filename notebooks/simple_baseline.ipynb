{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhf18v2MbqAs",
        "outputId": "53dc85db-f0de-4720-845b-6b9b2bfa53e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'dl2'...\n",
            "remote: Enumerating objects: 171, done.\u001b[K\n",
            "remote: Counting objects: 100% (171/171), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 171 (delta 50), reused 121 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (171/171), 65.11 KiB | 13.02 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "\n",
            "Current Directory:\n",
            "/content/dl2\n",
            "Collecting git+https://github.com/AMLab-Amsterdam/lie_learn\n",
            "  Cloning https://github.com/AMLab-Amsterdam/lie_learn to /tmp/pip-req-build-yg6xp9kh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AMLab-Amsterdam/lie_learn /tmp/pip-req-build-yg6xp9kh\n",
            "  Resolved https://github.com/AMLab-Amsterdam/lie_learn to commit 1ccc2106e402d517a29de5438c9367c959e67338\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Collecting escnn\n",
            "  Downloading escnn-1.0.11-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.9/373.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning\n",
            "  Downloading lightning-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lie_learn==0.0.1.post1) (2.31.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lie_learn==0.0.1.post1) (1.11.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from escnn) (1.4.0)\n",
            "Collecting pymanopt (from escnn)\n",
            "  Downloading pymanopt-2.2.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from escnn) (1.6.2)\n",
            "Collecting py3nj (from escnn)\n",
            "  Downloading py3nj-0.2.1.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.0)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.2.2-py3-none-any.whl (801 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.9/801.9 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch==2.2.1->torchvision) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->escnn) (0.18.3)\n",
            "Collecting scipy (from lie_learn==0.0.1.post1)\n",
            "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.1.post1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.1.post1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.1.post1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.1.post1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n",
            "Building wheels for collected packages: lie_learn, py3nj\n",
            "  Building wheel for lie_learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lie_learn: filename=lie_learn-0.0.1.post1-cp310-cp310-linux_x86_64.whl size=16176495 sha256=8e1a1a840a64d4a0005e1a43d7bcd9e51293b25a946c581cf07d8b74ca46e3b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7y47qb3s/wheels/3f/33/85/b8725ee77011bc42d77e4e35aeca2088482c3094f5c0a650a6\n",
            "  Building wheel for py3nj (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py3nj: filename=py3nj-0.2.1-cp310-cp310-linux_x86_64.whl size=44135 sha256=a5aba0c3533df13311d60d8c3bb7d7eaf7e98b8fcb9f3a2b93f8772c6e80f23f\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/e9/70/30a34ed6dbc8b54ce93f25c091be4cf7a24319e27d953a882b\n",
            "Successfully built lie_learn py3nj\n",
            "Installing collected packages: scipy, py3nj, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, pymanopt, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lie_learn, nvidia-cusolver-cu12, torchmetrics, escnn, pytorch-lightning, lightning\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "Successfully installed escnn-1.0.11 lie_learn-0.0.1.post1 lightning-2.2.2 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 py3nj-0.2.1 pymanopt-2.2.0 pytorch-lightning-2.2.2 scipy-1.9.3 torchmetrics-1.3.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import userdata\n",
        "    repo_name = 'dgcnz/dl2'\n",
        "    url = f\"https://{userdata.get('gh_pat')}@github.com/{repo_name}.git\"\n",
        "    !git clone {url}\n",
        "    print(\"\\nCurrent Directory:\")\n",
        "    %cd dl2\n",
        "    #!pip install torch torchvision numpy matplotlib git+https://github.com/AMLab-Amsterdam/lie_learn escnn scipy\n",
        "    !pip install torchvision git+https://github.com/AMLab-Amsterdam/lie_learn escnn lightning\n",
        "    #!pip install -r requirements.txt\n",
        "\n",
        "else: # automatically checks if the current directory is 'repo name'\n",
        "    curdir = Path.cwd()\n",
        "    print(\"Current Directory\", curdir)\n",
        "    assert curdir.name == \"dl2\" or curdir.parent.name == \"dl2\", \"Notebook cwd has to be on the project root\"\n",
        "    if curdir.name == \"notebooks\":\n",
        "        %cd ..\n",
        "        print(\"New Current Directory:\", curdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HCsuIxAbad22"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "\n",
        "import torch\n",
        "\n",
        "from escnn import gspaces\n",
        "from escnn import nn\n",
        "import os\n",
        "from torch import optim, utils, Tensor\n",
        "#from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import lightning as L\n",
        "from src.models.image_module import ImageLightningModule\n",
        "from src.data.rotated_mnist_datamodule import MnistRotDataset\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import RandomRotation\n",
        "from torchvision.transforms import Pad\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import InterpolationMode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS7msg3jad29"
      },
      "source": [
        "Using regular fields, 10 classes and 8 rotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tnN6MbeKad3A"
      },
      "outputs": [],
      "source": [
        "class C8SteerableCNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes=10):\n",
        "\n",
        "        super(C8SteerableCNN, self).__init__()\n",
        "\n",
        "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
        "        self.r2_act = gspaces.rot2dOnR2(N=8)\n",
        "\n",
        "        # the input image is a scalar field, corresponding to the trivial representation\n",
        "        in_type = nn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
        "\n",
        "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
        "        self.input_type = in_type\n",
        "\n",
        "        # convolution 1\n",
        "        # first specify the output type of the convolutional layer\n",
        "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 24*[self.r2_act.regular_repr])\n",
        "        self.block1 = nn.SequentialModule(\n",
        "            nn.MaskModule(in_type, 29, margin=1),\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 2\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block1.out_type\n",
        "        # the output type of the second convolution layer are 48 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
        "        self.block2 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool1 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 3\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block2.out_type\n",
        "        # the output type of the third convolution layer are 48 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
        "        self.block3 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 4\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block3.out_type\n",
        "        # the output type of the fourth convolution layer are 96 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
        "        self.block4 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool2 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 5\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block4.out_type\n",
        "        # the output type of the fifth convolution layer are 96 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
        "        self.block5 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 6\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block5.out_type\n",
        "        # the output type of the sixth convolution layer are 64 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 64*[self.r2_act.regular_repr])\n",
        "        self.block6 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool3 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
        "\n",
        "        self.gpool = nn.GroupPooling(out_type)\n",
        "\n",
        "        # number of output channels\n",
        "        c = self.gpool.out_type.size\n",
        "\n",
        "        # Fully Connected\n",
        "        self.fully_net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(c, 64),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ELU(inplace=True),\n",
        "            torch.nn.Linear(64, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor):\n",
        "        # wrap the input tensor in a GeometricTensor\n",
        "        # (associate it with the input type)\n",
        "        x = nn.GeometricTensor(input, self.input_type)\n",
        "\n",
        "        # apply each equivariant block\n",
        "\n",
        "        # Each layer has an input and an output type\n",
        "        # A layer takes a GeometricTensor in input.\n",
        "        # This tensor needs to be associated with the same representation of the layer's input type\n",
        "        #\n",
        "        # The Layer outputs a new GeometricTensor, associated with the layer's output type.\n",
        "        # As a result, consecutive layers need to have matching input/output types\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "\n",
        "        # pool over the spatial dimensions\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # pool over the group\n",
        "        x = self.gpool(x)\n",
        "\n",
        "        # unwrap the output GeometricTensor\n",
        "        # (take the Pytorch tensor and discard the associated representation)\n",
        "        x = x.tensor\n",
        "\n",
        "        # classify with the final fully connected layers)\n",
        "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a4baadee48294f1db6cec287817992a4",
            "c22f24d416954337912c2f0560a1727d",
            "1a863d0be4874b1c8468aab209ac48ba",
            "dfb989b693ea4d58b858d0871b25c93c",
            "1459e521473f48dda8ea4ee4b31f6a80",
            "233f67b79f1c43678d4ef2da193ffef0",
            "87d178b525a643caa2b05f6aa999e958",
            "df226b6400e24ba599f3fed7f783e217",
            "83e11805045a4a17b72c41451a4f0b57",
            "6c9bb99922ec4265afb374efe475433e",
            "3e326cc95e574c8ab61e131a868b0098"
          ]
        },
        "id": "gHfxBg2yad3C",
        "outputId": "136fe4a2-225a-42f2-a572-64f3f9953813"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name | Type           | Params\n",
            "----------------------------------------\n",
            "0 | net  | C8SteerableCNN | 2.1 M \n",
            "----------------------------------------\n",
            "2.1 M     Trainable params\n",
            "841       Non-trainable params\n",
            "2.1 M     Total params\n",
            "8.273     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name | Type           | Params\n",
            "----------------------------------------\n",
            "0 | net  | C8SteerableCNN | 2.1 M \n",
            "----------------------------------------\n",
            "2.1 M     Trainable params\n",
            "841       Non-trainable params\n",
            "2.1 M     Total params\n",
            "8.273     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4baadee48294f1db6cec287817992a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([64, 1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([1, 29, 29])\n",
            "torch.Size([64, 1, 29, 29])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "# define the LightningModule\n",
        "class LitModEquivariant(L.LightningModule):\n",
        "    def __init__(self, net):\n",
        "        super().__init__()\n",
        "        self.net = C8SteerableCNN()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch\n",
        "        #x = x.view(x.size(0), -1) idk waarom dit in die tutorial staat maar dit is een flatten opration vgm\n",
        "        print(x.shape)\n",
        "        #print(x.shape)\n",
        "        z = self.net(x)\n",
        "        loss = torch.nn.functional.cross_entropy(z, y)\n",
        "        # Logging to TensorBoard (if installed) by default\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "# init model\n",
        "net = C8SteerableCNN().to(device)\n",
        "equivariantmodel = LitModEquivariant(net)\n",
        "\n",
        "#define transforms\n",
        "pad = Pad((0, 0, 1, 1), fill=0)\n",
        "\n",
        "resize1 = Resize(87)\n",
        "resize2 = Resize(29)\n",
        "\n",
        "totensor = ToTensor()\n",
        "\n",
        "train_transform = Compose([\n",
        "    pad,\n",
        "    resize1,\n",
        "    RandomRotation(180., interpolation=InterpolationMode.BILINEAR, expand=False),\n",
        "    resize2,\n",
        "    totensor,\n",
        "])\n",
        "\n",
        "dataset = MnistRotDataset(\"data/mnist/\",download=True, transform=train_transform)\n",
        "train_loader = utils.data.DataLoader(dataset, batch_size = 64)\n",
        "\n",
        "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
        "trainer = L.Trainer(limit_train_batches=1, max_epochs=2) #for some reason error if you put max_epoch to 1 idk man\n",
        "trainer.fit(model=equivariantmodel, train_dataloaders=train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFzoZPKwlSL0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1459e521473f48dda8ea4ee4b31f6a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "1a863d0be4874b1c8468aab209ac48ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df226b6400e24ba599f3fed7f783e217",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83e11805045a4a17b72c41451a4f0b57",
            "value": 1
          }
        },
        "233f67b79f1c43678d4ef2da193ffef0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e326cc95e574c8ab61e131a868b0098": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c9bb99922ec4265afb374efe475433e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e11805045a4a17b72c41451a4f0b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87d178b525a643caa2b05f6aa999e958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4baadee48294f1db6cec287817992a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c22f24d416954337912c2f0560a1727d",
              "IPY_MODEL_1a863d0be4874b1c8468aab209ac48ba",
              "IPY_MODEL_dfb989b693ea4d58b858d0871b25c93c"
            ],
            "layout": "IPY_MODEL_1459e521473f48dda8ea4ee4b31f6a80"
          }
        },
        "c22f24d416954337912c2f0560a1727d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233f67b79f1c43678d4ef2da193ffef0",
            "placeholder": "​",
            "style": "IPY_MODEL_87d178b525a643caa2b05f6aa999e958",
            "value": "Epoch 1: 100%"
          }
        },
        "df226b6400e24ba599f3fed7f783e217": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb989b693ea4d58b858d0871b25c93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c9bb99922ec4265afb374efe475433e",
            "placeholder": "​",
            "style": "IPY_MODEL_3e326cc95e574c8ab61e131a868b0098",
            "value": " 1/1 [00:00&lt;00:00,  1.34it/s, v_num=6]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
