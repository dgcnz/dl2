{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import userdata\n",
        "    repo_name = 'dgcnz/dl2'\n",
        "    url = f\"https://{userdata.get('gh_pat')}@github.com/{repo_name}.git\"\n",
        "    !git clone {url}\n",
        "    print(\"\\nCurrent Directory:\")\n",
        "    %cd dl2\n",
        "    #!pip install torch torchvision numpy matplotlib git+https://github.com/AMLab-Amsterdam/lie_learn escnn scipy\n",
        "    !pip install torchvision git+https://github.com/AMLab-Amsterdam/lie_learn escnn lightning\n",
        "    #!pip install -r requirements.txt\n",
        "\n",
        "else: # automatically checks if the current directory is 'repo name'\n",
        "    curdir = Path.cwd()\n",
        "    print(\"Current Directory\", curdir)\n",
        "    assert curdir.name == \"dl2\" or curdir.parent.name == \"dl2\", \"Notebook cwd has to be on the project root\"\n",
        "    if curdir.name == \"notebooks\":\n",
        "        %cd ..\n",
        "        print(\"New Current Directory:\", curdir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhf18v2MbqAs",
        "outputId": "d5f2253d-3d6e-4185-9362-abfa89ecd5a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dl2'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 180 (delta 58), reused 124 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (180/180), 72.00 KiB | 4.50 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "\n",
            "Current Directory:\n",
            "/content/dl2\n",
            "Collecting git+https://github.com/AMLab-Amsterdam/lie_learn\n",
            "  Cloning https://github.com/AMLab-Amsterdam/lie_learn to /tmp/pip-req-build-4gi_p0sj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AMLab-Amsterdam/lie_learn /tmp/pip-req-build-4gi_p0sj\n",
            "  Resolved https://github.com/AMLab-Amsterdam/lie_learn to commit 1ccc2106e402d517a29de5438c9367c959e67338\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Collecting escnn\n",
            "  Downloading escnn-1.0.11-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.9/373.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning\n",
            "  Downloading lightning-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lie_learn==0.0.1.post1) (2.31.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lie_learn==0.0.1.post1) (1.11.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from escnn) (1.4.0)\n",
            "Collecting pymanopt (from escnn)\n",
            "  Downloading pymanopt-2.2.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from escnn) (1.6.2)\n",
            "Collecting py3nj (from escnn)\n",
            "  Downloading py3nj-0.2.1.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.0)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.2.2-py3-none-any.whl (801 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.9/801.9 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch==2.2.1->torchvision) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->escnn) (0.18.3)\n",
            "Collecting scipy (from lie_learn==0.0.1.post1)\n",
            "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.1.post1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.1.post1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.1.post1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lie_learn==0.0.1.post1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch==2.2.1->torchvision) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n",
            "Building wheels for collected packages: lie_learn, py3nj\n",
            "  Building wheel for lie_learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lie_learn: filename=lie_learn-0.0.1.post1-cp310-cp310-linux_x86_64.whl size=16176493 sha256=cf8138ad20dc07196b23d0055a15169f1449bde99880c7cf709399b91c6496f8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tlyxrg8f/wheels/3f/33/85/b8725ee77011bc42d77e4e35aeca2088482c3094f5c0a650a6\n",
            "  Building wheel for py3nj (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py3nj: filename=py3nj-0.2.1-cp310-cp310-linux_x86_64.whl size=44135 sha256=4ebb320f531323c61cb9acbb737a60540f0fb3552dd7d1d48840afa44c60db7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/e9/70/30a34ed6dbc8b54ce93f25c091be4cf7a24319e27d953a882b\n",
            "Successfully built lie_learn py3nj\n",
            "Installing collected packages: scipy, py3nj, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, pymanopt, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lie_learn, nvidia-cusolver-cu12, torchmetrics, escnn, pytorch-lightning, lightning\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "Successfully installed escnn-1.0.11 lie_learn-0.0.1.post1 lightning-2.2.2 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 py3nj-0.2.1 pymanopt-2.2.0 pytorch-lightning-2.2.2 scipy-1.9.3 torchmetrics-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HCsuIxAbad22"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "\n",
        "import torch\n",
        "\n",
        "from escnn import gspaces\n",
        "from escnn import nn\n",
        "import os\n",
        "from torch import optim, utils, Tensor\n",
        "#from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import lightning as L\n",
        "from src.models.image_module import ImageLightningModule\n",
        "from src.data.rotated_mnist_datamodule import MnistRotDataset\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import RandomRotation\n",
        "from torchvision.transforms import Pad\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import InterpolationMode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS7msg3jad29"
      },
      "source": [
        "Using regular fields, 10 classes and 8 rotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tnN6MbeKad3A"
      },
      "outputs": [],
      "source": [
        "class C8SteerableCNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes=10):\n",
        "\n",
        "        super(C8SteerableCNN, self).__init__()\n",
        "\n",
        "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
        "        self.r2_act = gspaces.rot2dOnR2(N=8)\n",
        "\n",
        "        # the input image is a scalar field, corresponding to the trivial representation\n",
        "        in_type = nn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
        "\n",
        "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
        "        self.input_type = in_type\n",
        "\n",
        "        # convolution 1\n",
        "        # first specify the output type of the convolutional layer\n",
        "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 24*[self.r2_act.regular_repr])\n",
        "        self.block1 = nn.SequentialModule(\n",
        "            nn.MaskModule(in_type, 29, margin=1),\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 2\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block1.out_type\n",
        "        # the output type of the second convolution layer are 48 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
        "        self.block2 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool1 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 3\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block2.out_type\n",
        "        # the output type of the third convolution layer are 48 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
        "        self.block3 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 4\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block3.out_type\n",
        "        # the output type of the fourth convolution layer are 96 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
        "        self.block4 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool2 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 5\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block4.out_type\n",
        "        # the output type of the fifth convolution layer are 96 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
        "        self.block5 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 6\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block5.out_type\n",
        "        # the output type of the sixth convolution layer are 64 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 64*[self.r2_act.regular_repr])\n",
        "        self.block6 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool3 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
        "\n",
        "        self.gpool = nn.GroupPooling(out_type)\n",
        "\n",
        "        # number of output channels\n",
        "        c = self.gpool.out_type.size\n",
        "\n",
        "        # Fully Connected\n",
        "        self.fully_net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(c, 64),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ELU(inplace=True),\n",
        "            torch.nn.Linear(64, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor):\n",
        "        # wrap the input tensor in a GeometricTensor\n",
        "        # (associate it with the input type)\n",
        "        x = nn.GeometricTensor(input, self.input_type)\n",
        "\n",
        "        # apply each equivariant block\n",
        "\n",
        "        # Each layer has an input and an output type\n",
        "        # A layer takes a GeometricTensor in input.\n",
        "        # This tensor needs to be associated with the same representation of the layer's input type\n",
        "        #\n",
        "        # The Layer outputs a new GeometricTensor, associated with the layer's output type.\n",
        "        # As a result, consecutive layers need to have matching input/output types\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "\n",
        "        # pool over the spatial dimensions\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # pool over the group\n",
        "        x = self.gpool(x)\n",
        "\n",
        "        # unwrap the output GeometricTensor\n",
        "        # (take the Pytorch tensor and discard the associated representation)\n",
        "        x = x.tensor\n",
        "\n",
        "        # classify with the final fully connected layers)\n",
        "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807,
          "referenced_widgets": [
            "7a315878ff0f49dc8950cf92237d3611",
            "3c10218815224f7d9a14ae11022c0b2c",
            "639ba796fc5c42919daf2c1057064873",
            "29ea06d99e9e450c908ba00901d629e1",
            "ce6d6a5d9def4694b7c09f1ecacad97e",
            "648a5f5b0a7e47c0b52c7bf209e41130",
            "669beab0ceee46b9a06ebe6e8c439022",
            "c2e15a01f5bf4575b54ff2fe75074077",
            "a5af1f47fea74be88a3c5bd0aed21172",
            "2194454e9fb84298bf222828af47a63b",
            "98b4cd7e19e148059d1b03c00fd721b7"
          ]
        },
        "id": "gHfxBg2yad3C",
        "outputId": "494bfb67-4299-4ad8-e7d6-29205d6da6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Download completed.\n",
            "Unzipping dataset...\n",
            "Unzip completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "WARNING: Missing logger folder: /content/dl2/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/dl2/lightning_logs\n",
            "INFO: \n",
            "  | Name | Type           | Params\n",
            "----------------------------------------\n",
            "0 | net  | C8SteerableCNN | 2.1 M \n",
            "----------------------------------------\n",
            "2.1 M     Trainable params\n",
            "841       Non-trainable params\n",
            "2.1 M     Total params\n",
            "8.273     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name | Type           | Params\n",
            "----------------------------------------\n",
            "0 | net  | C8SteerableCNN | 2.1 M \n",
            "----------------------------------------\n",
            "2.1 M     Trainable params\n",
            "841       Non-trainable params\n",
            "2.1 M     Total params\n",
            "8.273     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a315878ff0f49dc8950cf92237d3611"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 29, 29])\n",
            "torch.Size([64, 1, 29, 29])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "# define the LightningModule\n",
        "class LitModEquivariant(L.LightningModule):\n",
        "    def __init__(self, net):\n",
        "        super().__init__()\n",
        "        self.net = net\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch\n",
        "        #x = x.view(x.size(0), -1) idk waarom dit in die tutorial staat maar dit is een flatten opration vgm\n",
        "        print(x.shape)\n",
        "        #print(x.shape)\n",
        "        z = self.net(x)\n",
        "        loss = torch.nn.functional.cross_entropy(z, y)\n",
        "        # Logging to TensorBoard (if installed) by default\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "# init model\n",
        "net = C8SteerableCNN().to(device)\n",
        "equivariantmodel = LitModEquivariant(net)\n",
        "\n",
        "#define transforms\n",
        "pad = Pad((0, 0, 1, 1), fill=0)\n",
        "\n",
        "resize1 = Resize(87)\n",
        "resize2 = Resize(29)\n",
        "\n",
        "totensor = ToTensor()\n",
        "\n",
        "train_transform = Compose([\n",
        "    pad,\n",
        "    resize1,\n",
        "    RandomRotation(180., interpolation=InterpolationMode.BILINEAR, expand=False),\n",
        "    resize2,\n",
        "    totensor,\n",
        "])\n",
        "\n",
        "dataset = MnistRotDataset(\"data/mnist/\",download=True, transform=train_transform)\n",
        "train_loader = utils.data.DataLoader(dataset, batch_size = 64)\n",
        "\n",
        "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
        "trainer = L.Trainer(limit_train_batches=1, max_epochs=2) #for some reason error if you put max_epoch to 1 idk man\n",
        "trainer.fit(model=equivariantmodel, train_dataloaders=train_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Now create a similar sized non-equivariant CNN\n"
      ],
      "metadata": {
        "id": "wRvxyVkE2D5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicInvertedBottleneckBlock(torch.nn.Module):\n",
        "    def __init__(self, Cin, N, Cout, downsample = False, first_block = False):\n",
        "        super(BasicInvertedBottleneckBlock, self).__init__()\n",
        "\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "\n",
        "        if first_block:\n",
        "          kernel_size = 7\n",
        "          padding = 3\n",
        "\n",
        "        self.block = torch.nn.Sequential(\n",
        "          torch.nn.Conv2d(Cin, N, kernel_size=kernel_size, stride=1, padding=padding),\n",
        "          torch.nn.BatchNorm2d(N), #idk which BN to use\n",
        "          torch.nn.ELU(inplace=True),\n",
        "          #dit is de enige logische interpretatie van appendix H4 die ik kan bedenken. of miss dit of downsample maar nooit beide? dat is denk ik logischer\n",
        "          #torch.nn.Conv2d(N, Cout, kernel_size=kernel_size, stride=1, padding=padding)\n",
        "        )\n",
        "\n",
        "        self.one_by_one: bool = (Cin != Cout)\n",
        "\n",
        "        if self.one_by_one:\n",
        "            self.conv1x1 = torch.nn.Conv2d(Cin, Cout, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        if self.downsample:\n",
        "          #for this one I'm guessing\n",
        "          self.second_conv = torch.nn.Conv2d(N, Cout, kernel_size=kernel_size, stride=2, padding=padding)\n",
        "          self.avg_pool = torch.nn.AvgPool2d(kernel_size=kernel_size, stride=2, padding=padding)\n",
        "        else:\n",
        "          self.second_conv = torch.nn.Conv2d(N, Cout, kernel_size=kernel_size, stride=1, padding=padding) #idk setting kernel size to one here does massively reduce the number of parameters\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        print('before downsample')\n",
        "        print(out.shape)\n",
        "        print(x.shape)\n",
        "\n",
        "        out = self.second_conv(out)\n",
        "        if self.downsample:\n",
        "          #print('downsampled')\n",
        "          x = self.avg_pool(x)\n",
        "\n",
        "\n",
        "        print('afterdownsample')\n",
        "        print(out.shape)\n",
        "        print(x.shape)\n",
        "\n",
        "        if self.one_by_one:\n",
        "            x = self.conv1x1(x)\n",
        "\n",
        "        print('afteronebyone')\n",
        "        print(out.shape)\n",
        "        print(x.shape)\n",
        "        skip_connection = out + x\n",
        "        return skip_connection\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self, backbone_channels, residual_channels, n_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.backbone_channels = backbone_channels\n",
        "        self.residual_channels = residual_channels\n",
        "        self.blocks = self._make_blocks()\n",
        "        self.max_pool = torch.nn.MaxPool2d(kernel_size=3)\n",
        "\n",
        "        # Fully Connected\n",
        "        self.fully_net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(128, 64),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ELU(inplace=True),\n",
        "            torch.nn.Linear(64, n_classes),\n",
        "        )\n",
        "\n",
        "    def _make_blocks(self):\n",
        "        blocks = []\n",
        "        for i in range(len(self.backbone_channels)):\n",
        "            Cin = self.backbone_channels[i]\n",
        "            N = self.residual_channels[i]\n",
        "            # this next part is because their explanation doesnt seem to include the channel output size of the last block. So we set it to be the same as the input\n",
        "            if i < len(self.backbone_channels) - 1:\n",
        "                Cout = self.backbone_channels[i + 1]\n",
        "            else:\n",
        "                Cout = 128 #this is also very vague from the og paper\n",
        "\n",
        "            #print('hello', i)\n",
        "            if i == 0:\n",
        "              #print('i = 0 -------------------------')\n",
        "              blocks.append(BasicInvertedBottleneckBlock(Cin, N, Cout, first_block=True))\n",
        "\n",
        "            elif (i+1) % 2 == 0: #every two layers this is true\n",
        "              #print('True-------------------------------------------------------------')\n",
        "              blocks.append(BasicInvertedBottleneckBlock(Cin, N, Cout, downsample=True))\n",
        "\n",
        "            else:\n",
        "              #print('normal case =======================')\n",
        "              blocks.append(BasicInvertedBottleneckBlock(Cin, N, Cout))\n",
        "        return torch.nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.blocks(x)\n",
        "        out = self.max_pool(out)\n",
        "        print(out.shape)\n",
        "        out = self.fully_net(out.flatten(start_dim = 1))\n",
        "\n",
        "        return out\n",
        "\n",
        "# Example usage:\n",
        "backbone_channels = [1, 21, 54, 72, 108, 168]  # These are the C_in's\n",
        "residual_channels = [96, 192, 288, 288, 576, 576]  # These are the upsampled N's\n",
        "model = CNN(backbone_channels, residual_channels, n_classes = 10)\n",
        "\n"
      ],
      "metadata": {
        "id": "oFzoZPKwlSL0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_cnn = LitModEquivariant(model)\n",
        "cnn_trainer = L.Trainer(limit_train_batches=1, max_epochs=2) #for some reason error if you put max_epoch to 1 idk man\n",
        "cnn_trainer.fit(model=normal_cnn, train_dataloaders=train_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "219ce48f3d7d4ae69a9cb8efa17ecf2b",
            "7e1172784e4f4257897a0e61ba870c6f",
            "7c69b31b3d954e4f8879b37947426484",
            "8924c14fe1154c0ca5ee7b377818abc6",
            "8461ab32aab3491099933eedcba40831",
            "4b8d5d94992147eaa0d088bc419e8b03",
            "7034d72cf0b045bea11c385ac17e223f",
            "3b20f158cbaa411ba736dea08ec62e4e",
            "2480cf504f1c4e8fa29b30dcd4334809",
            "f6b5ba2074cc492ea26861965a9f5ed4",
            "3472ae45e2a044aeb6b0eeae13bf0d8a"
          ]
        },
        "id": "pCCwo8ui2wuI",
        "outputId": "fe3e8990-ab1b-4e69-a1fd-3779ab99ac7e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "INFO: \n",
            "  | Name | Type | Params\n",
            "------------------------------\n",
            "0 | net  | CNN  | 4.1 M \n",
            "------------------------------\n",
            "4.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.1 M     Total params\n",
            "16.241    Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name | Type | Params\n",
            "------------------------------\n",
            "0 | net  | CNN  | 4.1 M \n",
            "------------------------------\n",
            "4.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.1 M     Total params\n",
            "16.241    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "219ce48f3d7d4ae69a9cb8efa17ecf2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 29, 29])\n",
            "before downsample\n",
            "torch.Size([64, 96, 29, 29])\n",
            "torch.Size([64, 1, 29, 29])\n",
            "afterdownsample\n",
            "torch.Size([64, 21, 29, 29])\n",
            "torch.Size([64, 1, 29, 29])\n",
            "afteronebyone\n",
            "torch.Size([64, 21, 29, 29])\n",
            "torch.Size([64, 21, 29, 29])\n",
            "before downsample\n",
            "torch.Size([64, 192, 29, 29])\n",
            "torch.Size([64, 21, 29, 29])\n",
            "afterdownsample\n",
            "torch.Size([64, 54, 15, 15])\n",
            "torch.Size([64, 21, 15, 15])\n",
            "afteronebyone\n",
            "torch.Size([64, 54, 15, 15])\n",
            "torch.Size([64, 54, 15, 15])\n",
            "before downsample\n",
            "torch.Size([64, 288, 15, 15])\n",
            "torch.Size([64, 54, 15, 15])\n",
            "afterdownsample\n",
            "torch.Size([64, 72, 15, 15])\n",
            "torch.Size([64, 54, 15, 15])\n",
            "afteronebyone\n",
            "torch.Size([64, 72, 15, 15])\n",
            "torch.Size([64, 72, 15, 15])\n",
            "before downsample\n",
            "torch.Size([64, 288, 15, 15])\n",
            "torch.Size([64, 72, 15, 15])\n",
            "afterdownsample\n",
            "torch.Size([64, 108, 8, 8])\n",
            "torch.Size([64, 72, 8, 8])\n",
            "afteronebyone\n",
            "torch.Size([64, 108, 8, 8])\n",
            "torch.Size([64, 108, 8, 8])\n",
            "before downsample\n",
            "torch.Size([64, 576, 8, 8])\n",
            "torch.Size([64, 108, 8, 8])\n",
            "afterdownsample\n",
            "torch.Size([64, 168, 8, 8])\n",
            "torch.Size([64, 108, 8, 8])\n",
            "afteronebyone\n",
            "torch.Size([64, 168, 8, 8])\n",
            "torch.Size([64, 168, 8, 8])\n",
            "before downsample\n",
            "torch.Size([64, 576, 8, 8])\n",
            "torch.Size([64, 168, 8, 8])\n",
            "afterdownsample\n",
            "torch.Size([64, 128, 4, 4])\n",
            "torch.Size([64, 168, 4, 4])\n",
            "afteronebyone\n",
            "torch.Size([64, 128, 4, 4])\n",
            "torch.Size([64, 128, 4, 4])\n",
            "torch.Size([64, 128, 1, 1])\n",
            "torch.Size([64, 1, 29, 29])\n",
            "before downsample\n",
            "torch.Size([64, 96, 29, 29])\n",
            "torch.Size([64, 1, 29, 29])\n",
            "afterdownsample\n",
            "torch.Size([64, 21, 29, 29])\n",
            "torch.Size([64, 1, 29, 29])\n",
            "afteronebyone\n",
            "torch.Size([64, 21, 29, 29])\n",
            "torch.Size([64, 21, 29, 29])\n",
            "before downsample\n",
            "torch.Size([64, 192, 29, 29])\n",
            "torch.Size([64, 21, 29, 29])\n",
            "afterdownsample\n",
            "torch.Size([64, 54, 15, 15])\n",
            "torch.Size([64, 21, 15, 15])\n",
            "afteronebyone\n",
            "torch.Size([64, 54, 15, 15])\n",
            "torch.Size([64, 54, 15, 15])\n",
            "before downsample\n",
            "torch.Size([64, 288, 15, 15])\n",
            "torch.Size([64, 54, 15, 15])\n",
            "afterdownsample\n",
            "torch.Size([64, 72, 15, 15])\n",
            "torch.Size([64, 54, 15, 15])\n",
            "afteronebyone\n",
            "torch.Size([64, 72, 15, 15])\n",
            "torch.Size([64, 72, 15, 15])\n",
            "before downsample\n",
            "torch.Size([64, 288, 15, 15])\n",
            "torch.Size([64, 72, 15, 15])\n",
            "afterdownsample\n",
            "torch.Size([64, 108, 8, 8])\n",
            "torch.Size([64, 72, 8, 8])\n",
            "afteronebyone\n",
            "torch.Size([64, 108, 8, 8])\n",
            "torch.Size([64, 108, 8, 8])\n",
            "before downsample\n",
            "torch.Size([64, 576, 8, 8])\n",
            "torch.Size([64, 108, 8, 8])\n",
            "afterdownsample\n",
            "torch.Size([64, 168, 8, 8])\n",
            "torch.Size([64, 108, 8, 8])\n",
            "afteronebyone\n",
            "torch.Size([64, 168, 8, 8])\n",
            "torch.Size([64, 168, 8, 8])\n",
            "before downsample\n",
            "torch.Size([64, 576, 8, 8])\n",
            "torch.Size([64, 168, 8, 8])\n",
            "afterdownsample\n",
            "torch.Size([64, 128, 4, 4])\n",
            "torch.Size([64, 168, 4, 4])\n",
            "afteronebyone\n",
            "torch.Size([64, 128, 4, 4])\n",
            "torch.Size([64, 128, 4, 4])\n",
            "torch.Size([64, 128, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a315878ff0f49dc8950cf92237d3611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c10218815224f7d9a14ae11022c0b2c",
              "IPY_MODEL_639ba796fc5c42919daf2c1057064873",
              "IPY_MODEL_29ea06d99e9e450c908ba00901d629e1"
            ],
            "layout": "IPY_MODEL_ce6d6a5d9def4694b7c09f1ecacad97e"
          }
        },
        "3c10218815224f7d9a14ae11022c0b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_648a5f5b0a7e47c0b52c7bf209e41130",
            "placeholder": "​",
            "style": "IPY_MODEL_669beab0ceee46b9a06ebe6e8c439022",
            "value": "Epoch 1: 100%"
          }
        },
        "639ba796fc5c42919daf2c1057064873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e15a01f5bf4575b54ff2fe75074077",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5af1f47fea74be88a3c5bd0aed21172",
            "value": 1
          }
        },
        "29ea06d99e9e450c908ba00901d629e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2194454e9fb84298bf222828af47a63b",
            "placeholder": "​",
            "style": "IPY_MODEL_98b4cd7e19e148059d1b03c00fd721b7",
            "value": " 1/1 [00:07&lt;00:00,  0.13it/s, v_num=0]"
          }
        },
        "ce6d6a5d9def4694b7c09f1ecacad97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "648a5f5b0a7e47c0b52c7bf209e41130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "669beab0ceee46b9a06ebe6e8c439022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e15a01f5bf4575b54ff2fe75074077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5af1f47fea74be88a3c5bd0aed21172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2194454e9fb84298bf222828af47a63b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b4cd7e19e148059d1b03c00fd721b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "219ce48f3d7d4ae69a9cb8efa17ecf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e1172784e4f4257897a0e61ba870c6f",
              "IPY_MODEL_7c69b31b3d954e4f8879b37947426484",
              "IPY_MODEL_8924c14fe1154c0ca5ee7b377818abc6"
            ],
            "layout": "IPY_MODEL_8461ab32aab3491099933eedcba40831"
          }
        },
        "7e1172784e4f4257897a0e61ba870c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b8d5d94992147eaa0d088bc419e8b03",
            "placeholder": "​",
            "style": "IPY_MODEL_7034d72cf0b045bea11c385ac17e223f",
            "value": "Epoch 1: 100%"
          }
        },
        "7c69b31b3d954e4f8879b37947426484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b20f158cbaa411ba736dea08ec62e4e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2480cf504f1c4e8fa29b30dcd4334809",
            "value": 1
          }
        },
        "8924c14fe1154c0ca5ee7b377818abc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6b5ba2074cc492ea26861965a9f5ed4",
            "placeholder": "​",
            "style": "IPY_MODEL_3472ae45e2a044aeb6b0eeae13bf0d8a",
            "value": " 1/1 [00:01&lt;00:00,  0.81it/s, v_num=23]"
          }
        },
        "8461ab32aab3491099933eedcba40831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4b8d5d94992147eaa0d088bc419e8b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7034d72cf0b045bea11c385ac17e223f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b20f158cbaa411ba736dea08ec62e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2480cf504f1c4e8fa29b30dcd4334809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6b5ba2074cc492ea26861965a9f5ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3472ae45e2a044aeb6b0eeae13bf0d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}