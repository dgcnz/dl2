{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fhf18v2MbqAs",
    "outputId": "54c20458-f45b-4a3d-ad16-474b6a356f68"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    repo_name = \"dgcnz/dl2\"\n",
    "    url = f\"https://{userdata.get('gh_pat')}@github.com/{repo_name}.git\"\n",
    "    !git clone {url}\n",
    "    print(\"\\nCurrent Directory:\")\n",
    "    %cd dl2\n",
    "    #!pip install torch torchvision numpy matplotlib git+https://github.com/AMLab-Amsterdam/lie_learn escnn scipy\n",
    "    !pip install torchvision git+https://github.com/AMLab-Amsterdam/lie_learn escnn lightning wandb\n",
    "    #!pip install -r requirements.txt\n",
    "\n",
    "\n",
    "else:  # automatically checks if the current directory is 'repo name'\n",
    "    curdir = Path.cwd()\n",
    "    print(\"Current Directory\", curdir)\n",
    "    assert (\n",
    "        curdir.name == \"dl2\" or curdir.parent.name == \"dl2\"\n",
    "    ), \"Notebook cwd has to be on the project root\"\n",
    "    if curdir.name == \"notebooks\":\n",
    "        %cd ..\n",
    "        print(\"New Current Directory:\", curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ScCJVP4uqkw",
    "outputId": "18b965d7-f442-42b6-95df-9fa786c82ef2"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=userdata.get(\"wandb_key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "ZSXvCwp31174",
    "outputId": "c4465598-a2dd-4e33-ba4f-b3f83ebf0d66"
   },
   "outputs": [],
   "source": [
    "wandb.init(settings=wandb.Settings(start_method=\"fork\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCsuIxAbad22"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "from escnn import gspaces, nn\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torch import Tensor, optim, utils\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics import MaxMetric, MeanMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "# from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    InterpolationMode,\n",
    "    Pad,\n",
    "    RandomRotation,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "from src.data.rotated_mnist_datamodule import MnistRotDataset\n",
    "from src.models.image_module import ImageLightningModule\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owdETNajjM1m"
   },
   "source": [
    "###Set up pytorch lightning stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avGSx5qejQTL"
   },
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class PlModule(L.LightningModule):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.net = net\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # num classes\n",
    "        num_classes = 10  # net.layers[-1].out_features #if this break hardcode to one\n",
    "\n",
    "        # metric objects for calculating and averaging accuracy across batches\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "        self.train_loss = MeanMetric()\n",
    "        self.val_loss = MeanMetric()\n",
    "        self.test_loss = MeanMetric()\n",
    "\n",
    "        # for averaging loss across batches\n",
    "        self.train_acc_mean = MeanMetric()\n",
    "        self.val_acc_mean = MeanMetric()\n",
    "        self.test_acc_mean = MeanMetric()\n",
    "\n",
    "        # for tracking best so far validation accuracy\n",
    "        self.val_acc_best = MaxMetric()\n",
    "\n",
    "    def model_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Perform a single model step on a batch of data.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target labels.\n",
    "\n",
    "        :return: A tuple containing (in order):\n",
    "            - A tensor of losses.\n",
    "            - A tensor of predictions.\n",
    "            - A tensor of target labels.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.net(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        return loss, preds, y\n",
    "\n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n",
    "        \"\"\"Perform a single test step on a batch of data from the test set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        # print(batch_index)\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        self.test_loss(loss)\n",
    "        self.test_acc_mean(self.test_acc(preds, targets))\n",
    "        self.log(\"test/loss\", self.test_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/acc\", self.test_acc_mean, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n",
    "        \"\"\"Perform a single validation step on a batch of data from the validation set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        self.val_loss(loss)\n",
    "        self.val_acc_mean(self.val_acc(preds, targets))\n",
    "\n",
    "        self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/acc\", self.val_acc_mean, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.val_acc_mean.reset()\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Perform a single training step on a batch of data from the training set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        :return: A tensor of losses between model predictions and targets.\n",
    "        \"\"\"\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        self.train_loss(loss)\n",
    "        self.train_acc_mean(self.train_acc(preds, targets))\n",
    "\n",
    "        self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/acc\", self.train_acc_mean, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # return loss or backpropagation will fail\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        \"Lightning hook that is called when a training epoch ends.\"\n",
    "        self.train_acc_mean.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=5e-5, weight_decay=1e-5)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xS7msg3jad29"
   },
   "source": [
    "###C8 steerable cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnN6MbeKad3A"
   },
   "outputs": [],
   "source": [
    "class C8SteerableCNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes=10):\n",
    "\n",
    "        super(C8SteerableCNN, self).__init__()\n",
    "\n",
    "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
    "        self.r2_act = gspaces.rot2dOnR2(N=8)\n",
    "\n",
    "        # the input image is a scalar field, corresponding to the trivial representation\n",
    "        in_type = nn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
    "\n",
    "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
    "        self.input_type = in_type\n",
    "\n",
    "        # convolution 1\n",
    "        # first specify the output type of the convolutional layer\n",
    "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 24 * [self.r2_act.regular_repr])\n",
    "        self.block1 = nn.SequentialModule(\n",
    "            nn.MaskModule(in_type, 29, margin=1),\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "\n",
    "        # convolution 2\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block1.out_type\n",
    "        # the output type of the second convolution layer are 48 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 48 * [self.r2_act.regular_repr])\n",
    "        self.block2 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "        self.pool1 = nn.SequentialModule(\n",
    "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolution 3\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block2.out_type\n",
    "        # the output type of the third convolution layer are 48 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 48 * [self.r2_act.regular_repr])\n",
    "        self.block3 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "\n",
    "        # convolution 4\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block3.out_type\n",
    "        # the output type of the fourth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 96 * [self.r2_act.regular_repr])\n",
    "        self.block4 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "        self.pool2 = nn.SequentialModule(\n",
    "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolution 5\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block4.out_type\n",
    "        # the output type of the fifth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 96 * [self.r2_act.regular_repr])\n",
    "        self.block5 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "\n",
    "        # convolution 6\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block5.out_type\n",
    "        # the output type of the sixth convolution layer are 64 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 64 * [self.r2_act.regular_repr])\n",
    "        self.block6 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True),\n",
    "        )\n",
    "        self.pool3 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
    "\n",
    "        self.gpool = nn.GroupPooling(out_type)\n",
    "\n",
    "        # number of output channels\n",
    "        c = self.gpool.out_type.size\n",
    "\n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(c, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # wrap the input tensor in a GeometricTensor\n",
    "        # (associate it with the input type)\n",
    "        x = nn.GeometricTensor(input, self.input_type)\n",
    "\n",
    "        # apply each equivariant block\n",
    "\n",
    "        # Each layer has an input and an output type\n",
    "        # A layer takes a GeometricTensor in input.\n",
    "        # This tensor needs to be associated with the same representation of the layer's input type\n",
    "        #\n",
    "        # The Layer outputs a new GeometricTensor, associated with the layer's output type.\n",
    "        # As a result, consecutive layers need to have matching input/output types\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "\n",
    "        # pool over the spatial dimensions\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # pool over the group\n",
    "        x = self.gpool(x)\n",
    "\n",
    "        # unwrap the output GeometricTensor\n",
    "        # (take the Pytorch tensor and discard the associated representation)\n",
    "        x = x.tensor\n",
    "\n",
    "        # classify with the final fully connected layers)\n",
    "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHfxBg2yad3C",
    "outputId": "43396ff7-4a6b-447f-b1ef-cd8a423f74a0"
   },
   "outputs": [],
   "source": [
    "# init model\n",
    "net = C8SteerableCNN().to(device)\n",
    "equivariantmodel = PlModule(net)\n",
    "\n",
    "# define transforms\n",
    "pad = Pad((0, 0, 1, 1), fill=0)\n",
    "\n",
    "resize1 = Resize(87)\n",
    "resize2 = Resize(29)\n",
    "\n",
    "totensor = ToTensor()\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        pad,\n",
    "        resize1,\n",
    "        RandomRotation(180.0, interpolation=InterpolationMode.BILINEAR, expand=False),\n",
    "        resize2,\n",
    "        totensor,\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = Compose(\n",
    "    [\n",
    "        pad,\n",
    "        totensor,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "dataset = MnistRotDataset(\"data/mnist/\", download=True, transform=train_transform)\n",
    "test_dataset = MnistRotDataset(\n",
    "    \"data/mnist/\", download=False, train=False, transform=test_transform\n",
    ")\n",
    "\n",
    "train_loader1 = utils.data.DataLoader(dataset, batch_size=64, num_workers=7)\n",
    "test_loader1 = utils.data.DataLoader(test_dataset, batch_size=64, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c645b97c70fe453aad451e0f6dc6cc70",
      "90cda20358dc4417bb92d7cc47cd4c25",
      "51b5fc80888d49958f7a61ced6746af3",
      "6da663e49df54680aec2a11f8de7069e",
      "3591f75480a749949c684fbdcaeb2ac6",
      "6ab6be575f0942e39559fca3f4291e5c",
      "2b40a58278cb4e038ab2a4cefaafd008",
      "f84cde8022404c39aa793e94f3b0304d",
      "c33119c3e2ed4497bec612775ffaf2f7",
      "55152f85c355448dba12fe22e34e9623",
      "9256424fc3df4f89931aca8e9ced94f2",
      "fd65f0e7e56740f191931859070557c8",
      "6b50caf3b56b410fb66d3ee3bdbc94f0",
      "7df979b315cd4c009e5a892dd4a29976",
      "7b0477db3d534322a266ce4cfaf6dcb7",
      "e0182d631e9441c8a337ddaa30b8d1bd",
      "2a71f8d58ab043cba60f25298e01ecc8",
      "9f8423634b7240e3afbbb800a4e31a37",
      "d782d8a32d164e0a9b05b2c24c7fed76"
     ]
    },
    "id": "4krG7-S2tVEX",
    "outputId": "354ef37a-4094-4556-b403-67e1cc1f3990"
   },
   "outputs": [],
   "source": [
    "# create logger\n",
    "wandb.finish()\n",
    "c8steerable_logger = WandbLogger(\n",
    "    project=\"C8steerable_rotMNIST\", log_model=\"all\", name=\"first_epoch\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    every_n_epochs=2, save_top_k=-1, filename=\"c8model\"\n",
    ")  # every_n_epochs =2\n",
    "\n",
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=30, logger=c8steerable_logger, callbacks=[checkpoint_callback]\n",
    ")  # for some reason error if you put max_epoch to 1 idk man\n",
    "trainer.fit(\n",
    "    model=equivariantmodel, train_dataloaders=train_loader1\n",
    ")  # , val_dataloaders=test_loader1) #this is fine because the validation set is not used for anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "7fc82e9eee7b46eaba4b79c2836dc33d",
      "5cde11175d4c4092b6df89fbab96fc38",
      "74a4c5f976794a7188f5bb0b89fb2a2c",
      "4dda0db8fe494b8c960920a69d657b98",
      "0a859c8705f049d5b8ff9d5e798ad392",
      "55ef601a057d4decb2613ea189f40a7f",
      "7f63f9a86039499d9353cb8186c6747d",
      "bda4e55e77c74891875fea2794f233e2"
     ]
    },
    "id": "In3a4wX2VxGc",
    "outputId": "7b13cd05-70f3-41ae-9272-7782bf07fda9"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRvxyVkE2D5R"
   },
   "source": [
    "###Now create a similar sized non-equivariant CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFzoZPKwlSL0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicInvertedBottleneckBlock(torch.nn.Module):\n",
    "    def __init__(self, Cin, N, Cout, downsample=False, first_block=False):\n",
    "        super(BasicInvertedBottleneckBlock, self).__init__()\n",
    "\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "\n",
    "        if first_block:\n",
    "            kernel_size = 7\n",
    "            padding = 3\n",
    "\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(Cin, N, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(N),  # idk which BN to use\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            # dit is de enige logische interpretatie van appendix H4 die ik kan bedenken. of miss dit of downsample maar nooit beide? dat is denk ik logischer\n",
    "            # torch.nn.Conv2d(N, Cout, kernel_size=kernel_size, stride=1, padding=padding)\n",
    "        )\n",
    "\n",
    "        self.one_by_one: bool = Cin != Cout\n",
    "\n",
    "        if self.one_by_one:\n",
    "            self.conv1x1 = torch.nn.Conv2d(Cin, Cout, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            # for this one I'm guessing\n",
    "            self.second_conv = torch.nn.Conv2d(\n",
    "                N, Cout, kernel_size=kernel_size, stride=2, padding=padding\n",
    "            )\n",
    "            self.avg_pool = torch.nn.AvgPool2d(kernel_size=kernel_size, stride=2, padding=padding)\n",
    "        else:\n",
    "            self.second_conv = torch.nn.Conv2d(\n",
    "                N, Cout, kernel_size=kernel_size, stride=1, padding=padding\n",
    "            )  # idk setting kernel size to one here does massively reduce the number of parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        print(\"before downsample\")\n",
    "        print(out.shape)\n",
    "        print(x.shape)\n",
    "\n",
    "        out = self.second_conv(out)\n",
    "        if self.downsample:\n",
    "            # print('downsampled')\n",
    "            x = self.avg_pool(x)\n",
    "\n",
    "        print(\"afterdownsample\")\n",
    "        print(out.shape)\n",
    "        print(x.shape)\n",
    "\n",
    "        if self.one_by_one:\n",
    "            x = self.conv1x1(x)\n",
    "\n",
    "        print(\"afteronebyone\")\n",
    "        print(out.shape)\n",
    "        print(x.shape)\n",
    "        skip_connection = out + x\n",
    "        return skip_connection\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, backbone_channels, residual_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.backbone_channels = backbone_channels\n",
    "        self.residual_channels = residual_channels\n",
    "        self.blocks = self._make_blocks()\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "\n",
    "    def _make_blocks(self):\n",
    "        blocks = []\n",
    "        for i in range(len(self.backbone_channels)):\n",
    "            Cin = self.backbone_channels[i]\n",
    "            N = self.residual_channels[i]\n",
    "            # this next part is because their explanation doesnt seem to include the channel output size of the last block. So we set it to be the same as the input\n",
    "            if i < len(self.backbone_channels) - 1:\n",
    "                Cout = self.backbone_channels[i + 1]\n",
    "            else:\n",
    "                Cout = 128  # this is also very vague from the og paper\n",
    "\n",
    "            # print('hello', i)\n",
    "            if i == 0:\n",
    "                # print('i = 0 -------------------------')\n",
    "                blocks.append(BasicInvertedBottleneckBlock(Cin, N, Cout, first_block=True))\n",
    "\n",
    "            elif (i + 1) % 2 == 0:  # every two layers this is true\n",
    "                # print('True-------------------------------------------------------------')\n",
    "                blocks.append(BasicInvertedBottleneckBlock(Cin, N, Cout, downsample=True))\n",
    "\n",
    "            else:\n",
    "                # print('normal case =======================')\n",
    "                blocks.append(BasicInvertedBottleneckBlock(Cin, N, Cout))\n",
    "        return torch.nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.blocks(x)\n",
    "        out = self.max_pool(out)\n",
    "        print(out.shape)\n",
    "        out = self.fully_net(out.flatten(start_dim=1))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "backbone_channels = [1, 21, 54, 72, 108, 168]  # These are the C_in's\n",
    "residual_channels = [96, 192, 288, 288, 576, 576]  # These are the upsampled N's\n",
    "model = CNN(backbone_channels, residual_channels, n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZ_GNEKpw4CU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# V2\n",
    "\n",
    "\n",
    "class BasicInvertedBottleneckBlockV2(torch.nn.Module):\n",
    "    def __init__(self, Cin, N, Cout, downsample=False, first_block=False):\n",
    "        super(BasicInvertedBottleneckBlockV2, self).__init__()\n",
    "\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "\n",
    "        if first_block:\n",
    "            kernel_size = 7\n",
    "            padding = 3\n",
    "\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(Cin, N, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(N),  # idk which BN to use\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            # dit is de enige logische interpretatie van appendix H4 die ik kan bedenken. of miss dit of downsample maar nooit beide? dat is denk ik logischer\n",
    "            # torch.nn.Conv2d(N, Cout, kernel_size=kernel_size, stride=1, padding=padding)\n",
    "        )\n",
    "\n",
    "        self.one_by_one: bool = Cin != Cout\n",
    "\n",
    "        if self.one_by_one:\n",
    "            self.conv1x1 = torch.nn.Conv2d(Cin, Cout, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            # for this one I'm guessing\n",
    "            self.second_conv = torch.nn.Conv2d(\n",
    "                N, Cin, kernel_size=kernel_size, stride=2, padding=padding\n",
    "            )\n",
    "            self.avg_pool = torch.nn.AvgPool2d(kernel_size=kernel_size, stride=2, padding=padding)\n",
    "        else:\n",
    "            self.second_conv = torch.nn.Conv2d(\n",
    "                N, Cin, kernel_size=kernel_size, stride=1, padding=padding\n",
    "            )  # idk setting kernel size to one here does massively reduce the number of parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        # N Channels\n",
    "        # print('before downsample')\n",
    "        # print(out.shape)\n",
    "        # print(x.shape)\n",
    "\n",
    "        out = self.second_conv(out)\n",
    "        # C_in Channels\n",
    "\n",
    "        if self.downsample:\n",
    "            # if the second convolution downsamples\n",
    "            # then the size of the image changes\n",
    "            # so we must decrease x in size\n",
    "            # to be able to add it up\n",
    "            x = self.avg_pool(x)\n",
    "\n",
    "        # print('afterdownsample')\n",
    "        # print(out.shape)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # print('afteronebyone')\n",
    "        # print(out.shape)\n",
    "        # print(x.shape)\n",
    "        skip_connection = out + x\n",
    "        if self.one_by_one:\n",
    "            skip_connection = self.conv1x1(skip_connection)\n",
    "            # C_out\n",
    "\n",
    "        return skip_connection\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, backbone_channels, residual_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.backbone_channels = backbone_channels\n",
    "        self.residual_channels = residual_channels\n",
    "        self.blocks = self._make_blocks()\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=3, stride=1)  # This stride is sus\n",
    "\n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "\n",
    "    def _make_blocks(self):\n",
    "        blocks = []\n",
    "        for i in range(len(self.backbone_channels)):\n",
    "            Cin = self.backbone_channels[i]\n",
    "            N = self.residual_channels[i]\n",
    "            # this next part is because their explanation doesnt seem to include the channel output size of the last block. So we set it to be the same as the input\n",
    "            if i < len(self.backbone_channels) - 1:\n",
    "                Cout = self.backbone_channels[i + 1]\n",
    "            else:\n",
    "                Cout = 32  # We put this to 32, so it is 128/4, since we have a 2x2 output\n",
    "\n",
    "            # print('hello', i)\n",
    "            if i == 0:\n",
    "                # print('i = 0 -------------------------')\n",
    "                blocks.append(BasicInvertedBottleneckBlockV2(Cin, N, Cout, first_block=True))\n",
    "\n",
    "            elif (i + 1) % 2 == 0:  # every two layers this is true\n",
    "                # print('True-------------------------------------------------------------')\n",
    "                blocks.append(BasicInvertedBottleneckBlockV2(Cin, N, Cout, downsample=True))\n",
    "\n",
    "            else:\n",
    "                # print('normal case =======================')\n",
    "                blocks.append(BasicInvertedBottleneckBlockV2(Cin, N, Cout))\n",
    "        return torch.nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.blocks(x)\n",
    "        out = self.max_pool(out)\n",
    "        # print(out.shape)\n",
    "        out = self.fully_net(out.flatten(start_dim=1))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "backbone_channels = [1, 21, 54, 72, 108, 168]  # These are the C_in's\n",
    "residual_channels = [96, 192, 288, 288, 576, 576]  # These are the upsampled N's\n",
    "model = CNN(backbone_channels, residual_channels, n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0594bbdc401240c0b3d316a4562f4f62",
      "9c489cbb2e6e4f68a892581f373d97fa",
      "e74e0a997d61400c8b01b7c0afe8efa0",
      "f1fb1ececd3b42d58152eb4638c93ff6",
      "e00870aaee084ddfa86f2402a3751974",
      "4d793574e83941a69c98861bb0ffded4",
      "6a6682dcf94a478db926d71cb1789299",
      "fe70f420f5314a2d9ad3d0958b16298f",
      "c2546cd3e3204742898b1fa79953f0fe",
      "c6361aecae5149708f525da6b156e815",
      "36db033d7b334b4287c41795831406aa"
     ]
    },
    "id": "pCCwo8ui2wuI",
    "outputId": "187dbecd-51d3-46ff-e38b-ee3bd136feca"
   },
   "outputs": [],
   "source": [
    "normal_cnn = PlModule(model)\n",
    "\n",
    "train_loader2 = utils.data.DataLoader(dataset, batch_size=64, num_workers=7)\n",
    "\n",
    "wandb.finish()\n",
    "cnn_logger = WandbLogger(project=\"CNN_rotMNIST\", log_model=\"all\", name=\"first_cnn_run\")\n",
    "\n",
    "checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    every_n_epochs=2, save_top_k=-1, filename=\"cnn_model\"\n",
    ")\n",
    "\n",
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "cnn_trainer = L.Trainer(\n",
    "    max_epochs=30, logger=cnn_logger, callbacks=[checkpoint_callback]\n",
    ")  # for some reason error if you put max_epoch to 1 idk man\n",
    "cnn_trainer.fit(\n",
    "    model=normal_cnn, train_dataloaders=train_loader1\n",
    ")  # , val_dataloaders=test_loader1) #this is fine because the validation set is not used for anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "9f2c37604a4245d79e9664326ecc5ff2",
      "dda83bb068b34be0a9e0c45fdecaac62",
      "2622ea3ac20144029a1557cd6115a14a",
      "c32cb7c2249849d9a853625e3ca708af",
      "25d1d2737d364b32a86617138c8ae36a",
      "082351a203294dc39b2e3c4de82ea4c4",
      "825c3b53f0ef43bf8a362046c0faa1f5",
      "170f11e18c574d1fb6f224dcfe12246d"
     ]
    },
    "id": "-1iwIjoZZCg2",
    "outputId": "b08b28d6-93db-4d9e-85df-efd0fd440830"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
