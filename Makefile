VENV           = .venv
VENV_PYTHON    = $(VENV)/bin/python
# make it work on windows too
ifeq ($(OS), Windows_NT)
    VENV_PYTHON=$(VENV)/Scripts/python
endif
SYSTEM_PYTHON  = $(or $(shell which python3), $(shell which python))
PYTHON = $(VENV_PYTHON)

help:  ## Show help
	@grep -E '^[.a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'

clean: ## Clean autogenerated files
	rm -rf dist
	find . -type f -name "*.DS_Store" -ls -delete
	find . | grep -E "(__pycache__|\.pyc|\.pyo)" | xargs rm -rf
	find . | grep -E ".pytest_cache" | xargs rm -rf
	find . | grep -E ".ipynb_checkpoints" | xargs rm -rf
	rm -f .coverage

clean-logs: ## Clean logs
	rm -rf logs/**

format: ## Run pre-commit hooks
	pre-commit run -a

sync: ## Merge changes from main branch to your current branch
	git pull
	git pull origin main

test: ## Run not slow tests
	$(PYTHON) -m pytest -k "not slow"

test-full: ## Run all tests
	$(PYTHON) -m pytest

train: ## Train the model
	$(PYTHON) src/train.py


send_key: ## Sends public key to snellius
	ssh-copy-id -i ~/.ssh/surf dl2

module_avail: ## greppable module avail
	module -t avail 2>&1

load_modules:
	module load 2023
	module load Python/3.11.3-GCCcore-12.3.0

unload_modlues:
	module unload Python/3.11.3-GCCcore-12.3.0
	module unload 2023

setup_env: # setup the virtual environment and download dependencies
	$(SYSTEM_PYTHON) -m venv .venv
	$(PYTHON) -m pip install poetry
	$(PYTHON) -m poetry install

scat: ## cat slurm log with param
	cat scripts/slurm_logs/slurm_output_$(id).out

strain:
	sbatch scripts/slurm/train.sh $(experiment)

strain_10:
	sbatch scripts/slurm/train_10.sh $(experiment)

strain_multiseed: # make strain_10_multiseed experiment=exp seeds="10 20"
	for seed in $(seeds); do \
		sbatch scripts/slurm/train_seed.sh $(experiment) $$seed; \
	done


strain_10_multiseed: # make strain_10_multiseed experiment=exp seeds="10 20"
	for seed in $(seeds); do \
		sbatch scripts/slurm/train_10_seed.sh $(experiment) $$seed; \
	done

strain_multirun:
	sbatch scripts/slurm/train_multirun.sh $(experiment)

secho: # check that there is experiment
	sbatch scripts/slurm/echo.sh $(experiment)

test_wang2022_table_1:
	python -m src.train experiment=wang2022/rotation/rgroup_2022_vec +trainer.fast_dev_run=True data.batch_size=2 trainer.accelerator=cpu
	python -m src.train experiment=wang2022/rotation/rsteer +trainer.fast_dev_run=True data.batch_size=2 trainer.accelerator=cpu
	python -m src.train experiment=wang2022/rotation/convnet +trainer.fast_dev_run=True data.batch_size=2 trainer.accelerator=cpu
	python -m src.train experiment=wang2022/rotation/e2conv +trainer.fast_dev_run=True data.batch_size=2 trainer.accelerator=cpu

test_wang2022_figure_4:
	python -m src.train experiment=wang2022/equivariance_test/rgroup +trainer.fast_dev_run=True data.batch_size=8
	python -m src.train experiment=wang2022/equivariance_test/rsteer +trainer.fast_dev_run=True data.batch_size=8
	python -m src.train experiment=wang2022/equivariance_test/convnet +trainer.fast_dev_run=True data.batch_size=8

test_wang2024:
	python -m src.train experiment=wang2024/rgcnn_single +trainer.fast_dev_run=True data.batch_size=1 trainer.accelerator=cpu data.num_workers=0 data.dataset_config_name=small_50
	python -m src.train experiment=wang2024/rgcnn +trainer.fast_dev_run=True data.batch_size=1 trainer.accelerator=cpu data.num_workers=0 data.dataset_config_name=small_50
	python -m src.train experiment=wang2024/gcnn +trainer.fast_dev_run=True data.batch_size=1 trainer.accelerator=cpu data.num_workers=0 data.dataset_config_name=small_50

printid:
	cat scripts/slurm_logs/slurm_output_$(id).out | grep "View run * at"

get_local_checkpoints:
	@echo "Finding checkpoints for wandb run id: $(id)"
	@RUNPATH=$$(find logs/train/runs -type d -name ${id}); \
    echo "Found run path: $$RUNPATH"; \
	echo "Checkpoints:"; \
	ls $$RUNPATH/checkpoints
